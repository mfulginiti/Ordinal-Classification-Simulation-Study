---
title: "Ordinal_Classification_Simulation_Study"
author: "Mark Fulginiti"
date: "3/23/2021"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
---

\newpage

# *Introduction*

Falsification of survey responses is common amongst individuals for numerous reasons.  It can be due to social desirability, bias, or the desire to achieve certain goals, and can further be either conscious, or unconscious&nbsp;behavior. 

Multiple methods have been developed to help analyze the problem of falsified survey responses such as coached falsification, ad-lib falsification, and sample generation by replacement (SGR), each of which makes use of ad-hoc empirical&nbsp;paradigms.

In order to study the effects of falsification by respondents in various classification settings, multiple simulation studies under various scenarios of data perturbation, i.e., data falsification, using the sample generation by replacement (SGR) method were performed.


# *Sample Generation by Replacement (SGR)*
*(Lombardi and Pastore 2014)*

## *SGR Framework:*

SGR is a two-stage sampling procedure based on two distinct generative models:

1. Real / simulated data representing the true data (data generation process)
   - Monte Carlo procedures for ordinal data
 
2. Model representing faking process to perturb data (data replacement process)
   - Implemented using ad hoc probabilistic perturbation models


The data generation process and the data replacement process are independent.


### *General Data Generation Process:*

Begin with matrix $\textbf{D}_{n \times m}$ with $n$ observations and $m$ variables (elements).  

Each entry $d_{ij},~~(i=1,...,n;~~j=1,...,m)$ takes on a small ordinal range $V_q = \{1,...,q\}\text{.}$  For the time being, assume all $V_q$ are identical ordinal scales, but this need not be true for SGR to work.

Let $\textbf{d}_i$ be the $(1 \times m)$ array of $\textbf{D}_{n \times m}$ denoting the response pattern for $\text{participant }i\text{.}$  $\textbf{d}_i$ is a multidimensional ordinal random variable with probability distribution $p \left( \textbf{d}_i \mid \theta_D \right)\text{,}$ where $\theta_D$ indicates the vector of parameters of the probabilistic model for the data generation process.

***Although the R-SGR package provides a function for simulating ordinal data, the data generation process used in this report was derived separately and is entirely independent of the SGR package.  The SGR package was used entirely for the convenience of the data replacement process.***

### *General Data Replacement Process:*

Construct a new ordinal (perturbed) data matrix $\textbf{F}_{n \times m}$ of $\textbf{D}_{n \times m}$ by manipulating each element $d_{ij}$ in $\textbf{D}_{n \times m}$ according to a replacement probability distribution.

Let $\textbf{f}_i$ be the $(1 \times m)$ array of $\textbf{F}_{n \times m}$ denoting the replaced pattern of perturbed responses for $\text{participant }i\text{.}$  $\textbf{f}_i$ is a multidimensional ordinal random variable with conditional replacement probability distribution
$$p \left( \textbf{f}_i \mid \textbf{d}_{i},~\theta_F \right)=\prod_{j=1}^m~p \left( f_{ij} \mid d_{ij},~\theta_F \right),~~(i=1,...,n;~~j=1,...,m)$$ 
where $\theta_F$ indicates the vector of parameters of the probabilistic perturbation model for the data replacement process.

#### *Note:*

In the standard SGR framework, the replacement distribution $p \left( \textbf{f}_i \mid \textbf{d}_{i},~\theta_F \right)$ is restricted to satisfy the conditional independence (CI) assumption.  Each $f_{ij}$ depends only on the corresponding data observation $d_{ij}$ and the model parameters $\theta_F\text{.}$  Because the patterns of false responses are also identical and independently distributed *(i.i.d.)* observations, the simulated data array $\left(\textbf{D}_{n \times m}, \textbf{F}_{n \times m}\right)$ is drawn from the joint probability distribution


\begin{align*}
p \left( \textbf{D},\textbf{F} \mid \theta_D,~\theta_F \right) &= \prod_{i=1}^n~p \left( \textbf{d}_{i} \mid \theta_D \right) p \left( \textbf{f}_{i} \mid \textbf{d}_{i},~\theta_F \right) \\  &= \prod_{i=1}^n~p \left( \textbf{d}_{i} \mid \theta_D \right) \prod_{j=1}^m~p \left(f_{ij} \mid d_{ij},~\theta_F \right)
\end{align*}


### *Data Generation Process in R-SGR*


The sgr package currently uses a procedure based on the multivariate latent variable framework called the underlying variable approach (UVA). 

Assume that there exists a continuous data matrix $\textbf{D}_{n \times m}^*$ underlying the ordinal data $\text{matrix }\textbf{D}_{n \times m}\text{.}$  Let $\textbf{d}_{i}^*$ be the $(1 \times m)$ array of $\textbf{D}_{n \times m}^*$ denoting the pattern of underlying continuous values of the $i^{\text{th}}$ observation.  Let $\textbf{d}_{i}^*$ have the multivariate $N(0,1)$ distribution with density function $\phi(0,R)$ where $R$ denotes the $(m \times m)$ correlation matrix.  The connection between $d_{ij}$ and $d_{ij}^*$ in $\textbf{D}_{n \times m}^*$ is given by


$$d_{ij} = h ~~~~~~\text{ iff }~~~~~~ \tau_{h-1}^{j} < d_{ij}^{*} \le \tau_{h}^{j}$$

with $h=1,...,q;~~~i=1,...,n;~~~j=1,...,m$ and for the purposes of the sgr package syntax,

$$-\infty = \tau_{0}^j < \tau_{1}^j < \tau_{2}^j < ~...~ < \tau_{q-1}^j < \tau_{q}^j = \infty$$
are threshold parameters.  Therefore, the joint probability of $\textbf{d}_{i} = (h_1,...,h_m)$ is given by

$$p\left(\textbf{h} \mid \theta_M\right) = \int_{\tau_{h_1-1}^1}^{\tau_{h_1}^1} ~...~ \int_{\tau_{h_m-1}^m}^{\tau_{h_m}^m} ~\phi\left(\textbf{z} \mid \textbf{0},\textbf{R}\right)d\textbf{z}$$
with $\theta_M = \left(\tau, \textbf{R}\right) \text{  and  } \textbf{z} = (z_1,...,z_m)$ being the parameter vector of the original data generation model, and the values (z-scores) for the continuous variables, respectively.

In the sgr package, the data generation process is obtained by first generating the continuous data $\textbf{D}_{n \times m}^*$ according to a model correlation matrix $\textbf{R}$ and then by transforming it to its discrete counterpart $\textbf{D}_{n \times m}$ using the model $\text{thresholds } \tau \text{.}$


### *Data Replacement Process in R-SGR*


Let $p_{k \mid h} \equiv p(k \mid h,\theta_F)$ be the conditional probability of replacing an original ordinal value $h$ with a new ordinal value $k\text{.}$  In general, $\theta_F$ represents hypothetical a priori knowledge about the distribution of falsification (e.g., the chance of observing a falsified observation in the data) or empirically based knowledge about the process of falsification (e.g., the direction of falsification - positive vs negative).  

The conditional replacement distribution can be described by

\begin{equation*}
  p_{k \mid h}=\left\{
  \begin{array}{@{}cc@{}}
    DG(k;a^+,b^+,\theta_F^+) \pi^+, & \ 1 \le h < k \le q \\
    DG(k;a^-,b^-,\theta_F^-) \pi^-, & \ 1 \le k < h \le q \\
    1-(\pi^+ + \pi^-), & \ 1 < k = h < q \\
    1-\pi^+, & \ k=h=1 \\
    1-\pi^-, & \ k=h=q
  \end{array}\right.
\end{equation*} 

with $DG$ being the generalized beta distribution for discrete variables.  The first and second lines in the function model the behavior of positive $(k>h)$ and negative $(k<h)$ falsification, respectively.  The shape parameter is $\theta_F^+ = (\gamma^+,\delta^+)$ with bounds $(a^+ = h+1, b^+=q)$ for the first line and $\theta_F^- = (\gamma^-,\delta^-)$ with bounds $(a^- = 1, b^-=h-1)$ for the second line.

The three default shapes for the generalized beta distribution used in this report are the uniform, slight, and extreme.  When $\gamma=\delta=1\text{,}$ the replacement distribution reduces to a uniform support falsified distribution.  When $1\le \gamma < \delta\text{,}$ the model mimics asymmetric falsification configurations corresponding to a slight shift in the value of the original response.  When $1\le \delta < \gamma\text{,}$ the model mimics asymmetric falsification configurations corresponding to an extreme shift in the value of the original response.

$$~$$


```{r, beta plot, cache=TRUE, echo=FALSE, fig.asp=0.5}
suppressPackageStartupMessages(suppressWarnings(library(tidyverse)))

Slight <- rbeta(n = 10000000, shape1 = 1.5, shape2 = 4)
Uninformative <- rbeta(n = 10000000, shape1 = 1, shape2 = 1)
Extreme <- rbeta(n = 10000000, shape1 = 4, shape2 = 1.5)

beta <- data.frame(Slight, Uninformative, Extreme) %>% pivot_longer(cols = everything())

beta$name <- factor(beta$name, levels = c("Slight", "Uninformative", "Extreme"))


beta_plot <- ggplot(data = beta) +
   geom_density(aes(value, group = name, color = name), size = 1.5) +
   scale_color_manual(breaks = c("Slight", "Uninformative", "Extreme"), 
                      values = c("#7CAE00", "#00BFC4", "#C77Cff")) +
   scale_y_continuous(name = NULL, breaks = seq(0,2.5,0.5), limits = c(0,2.5)) +
   scale_x_continuous(name = "Percentile", breaks = seq(0,1,0.1)) +
   labs(title = "Beta Density Curves for Model Perturbation Type:", 
        subtitle = "Slight, Uninformative, and Extreme",
        caption = "Beta density curves for observations perturbed in the positive direction. \n When observations are perturbed in the negative direction, \n the slight and extreme density curves are reversed.") +
   theme(legend.position = "bottom",legend.title = element_blank())

beta_plot
```



```{r, SGR plot rsgr, echo=FALSE, fig.align='center', fig.cap="Three examples of conditional replacement distributions for a 7-point discrete random variable. Each column in the graphical representation corresponds to a different conditional replacement distribution. For each example the overall probabilities are p(+) = 0.6 and p(-) = 0.0 (faking positive only condition). Each row in the graphical representation corresponds to a different original 7-point discrete value h. (Lombardi and Pastore 2014)"}

knitr::include_graphics("/Users/Mark/Desktop/Data Science Projects/Ordinal_Classification_Simulation_Study/SGR_plot_rsgr.png",
dpi = 250)
```

$$~$$
```{r, default parameters, echo=FALSE, eval=FALSE}

scenarios <- tribble(
   ~Model, ~gamma_plus, ~gamma_neg, ~delta_plus, ~delta_neg,
   'uninformative', 1, 1, 1, 1,
   'slight', 1.5, 4, 4, 1.5,
   'extreme', 4, 1.5, 1.5, 4)

table_1 <- xtable::xtable(scenarios, caption = "Default parameter assignments for replacement model in R-SGR.", digits = c(rep(1,6)), align = rep("c",6))

xtable::print.xtable(table_1, include.rownames = FALSE)


```


$$~$$
\begin{table}[!ht]
\centering
\begin{tabular}{ccccc}
  \hline
Model & $\gamma^+$ & $\gamma^-$ & $\delta^+$ & $\delta^-$ \\ 
  \hline
uninformative & 1.0 & 1.0 & 1.0 & 1.0 \\ 
  slight & 1.5 & 4.0 & 4.0 & 1.5 \\ 
  extreme & 4.0 & 1.5 & 1.5 & 4.0 \\
   \hline
\end{tabular}
\caption{Default parameter assignments for replacement model in R-SGR.  The shape parameters can be altered manually as needed.} 
\end{table}



\newpage
$$~$$
\newpage

# *Simulations for Binary Classification*

How much of a change will we see in the misclassification rate when different falsification scenarios are applied to the data? Data were created using the following distributions and subjected to perturbation under the following&nbsp;scenarios.



```{r, histograms for ordinal distributions, echo=FALSE, fig.asp=0.6}
suppressPackageStartupMessages(suppressWarnings(library(tidyverse)))


abc <- tribble(
   ~ Ord_Val, ~ Prop, ~ grp,
   "1",    2.5,    "Normal",
   "2",    13.5,   "Normal",
   "3",    68,     "Normal",
   "4",    13.5,   "Normal",
   "5",    2.5,    "Normal",
   "1",    10,     "Triangular",
   "2",    20,     "Triangular",
   "3",    40,     "Triangular",
   "4",    20,     "Triangular",
   "5",    10,     "Triangular",
   "1",    17,     "Near Uniform",
   "2",    20,     "Near Uniform",
   "3",    26,     "Near Uniform",
   "4",    20,     "Near Uniform",
   "5",    17,     "Near Uniform",
   "1",    30,     "Right Skewed",
   "2",    25,     "Right Skewed",
   "3",    20,     "Right Skewed",
   "4",    15,     "Right Skewed",
   "5",    10,     "Right Skewed",
   "1",    10,     "Left Skewed",
   "2",    15,     "Left Skewed",
   "3",    20,     "Left Skewed",
   "4",    25,     "Left Skewed",
   "5",    30,     "Left Skewed",
   "1",    25,     "Bi-modal",
   "2",    20,     "Bi-modal",
   "3",    10,     "Bi-modal",
   "4",    20,     "Bi-modal",
   "5",    25,     "Bi-modal",
)

abc$grp <- factor(abc$grp, levels = c("Normal", "Triangular", "Near Uniform", "Right Skewed", 
                                      "Left Skewed", "Bi-modal"))

ggplot(abc, aes(x = Ord_Val, y = Prop)) +
   geom_col(color = "black", fill = "dark blue") +
   scale_y_continuous(name = "Proportion ", breaks = seq(0, 100, 10),
                      labels = seq(0, 100, 10), limits = c(0,100)) +
   geom_text(aes(label = Prop, vjust = -0.8)) +
   facet_wrap(~grp) +
   xlab("Ordinal Levels") +
   ggtitle("Distributions for Independent Variables")

```


```{r, scenario table, echo=FALSE, eval=FALSE}

scenarios <- tribble(
   ~Scenario, ~Positive_Falsification, ~Negative_Falsification,
   1, 25, 0,
   2, 50, 0,
   3, 75, 0,
   4, 100, 0,
   5, 0, 25,
   6, 25, 25,
   7, 50, 25,
   8, 75, 25,
   9, 0, 50,
   10, 25, 50,
   11, 50, 50,
   12, 0, 75,
   13, 25, 75,
   14, 0, 100)

table_2 <- xtable::xtable(scenarios, caption = "Perturbation Scenarios for Replacement: Percentages of the original data being replaced. For each scenario, the uninformative, slight, and extreme conditional replacement models were used and the misclassification distributions for each perturbed dataset was simulated for comparison to the original \"historical\" misclassification distribution.  It is important to note that when all independent variables in a model are both symmetrical and i.i.d., several of the scenarios will be equivalent.", digits = c(rep(0,4)), align = rep("c",4))

xtable::print.xtable(table_2, include.rownames = FALSE)


```



\begin{table}[!ht]
\centering
\begin{tabular}{ccc}
  \hline
Scenario & Positive Falsification & Negative Falsification \\ 
  \hline
1 & 25 & 0 \\ 
  2 & 50 & 0 \\ 
  3 & 75 & 0 \\ 
  4 & 100 & 0 \\ 
  5 & 0 & 25 \\ 
  6 & 25 & 25 \\ 
  7 & 50 & 25 \\ 
  8 & 75 & 25 \\ 
  9 & 0 & 50 \\ 
  10 & 25 & 50 \\ 
  11 & 50 & 50 \\ 
  12 & 0 & 75 \\ 
  13 & 25 & 75 \\ 
  14 & 0 & 100 \\ 
   \hline
\end{tabular}
\caption{Perturbation Scenarios for Replacement: Percentages of the original data being replaced. For each scenario, the uninformative, slight, and extreme conditional replacement models were used and the misclassification distributions for each perturbed dataset was simulated for comparison to the original "historical" misclassification distribution.  It is important to note that when all independent variables in a model are both symmetrical and i.i.d., several of the scenarios will be equivalent.} 
\end{table}


\newpage


## *Section I: 5 Independent Variables, Normally Distributed*

We have a survey with 5 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable is normally distributed.  The historical model of best fit has been determined to be 


$$logit(Y) = -3 + 0.9x_1 - 0.85x_2 + 0.8x_3 - 0.75x_4 + 0.7x_5$$

$$~$$

```{r, historical misclassification distribution 1, echo=FALSE, cache=TRUE}


nobs <- 1000




set.seed(1234)  # The seed makes the following exactly reproducible


miss_vec <- c()
for(b in 1:1000){
   
n <- 5

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5)

# summary(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_1 <- data.frame(Historical_1_Historical = miss_vec)

```

```{r, simulation function 1, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
#  

sim_func_1 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 5                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5)                                     #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-3 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
0.75*data_pert$x4 + 0.7*data_pert$x5)                                         ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_pert, family = "binomial")           ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 1, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_1 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_1[[paste0("Uninformative_1_Scenario_",ind)]] <- sim_func_1(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_1 <- as.data.frame(uninformative_1)

```

```{r, slight 1, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_1 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_1[[paste0("Slight_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_1 <- as.data.frame(slight_1)

```

```{r, extreme 1, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_1 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_1[[paste0("Extreme_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_1 <- as.data.frame(extreme_1)

```

```{r, summary 1, echo=FALSE, cache=TRUE}

df_1 <- tibble(historical_1, uninformative_1, slight_1, extreme_1) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_1_")

df_1$Scenario <- factor(df_1$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_1$Model <- factor(df_1$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


plot_1 <- ggplot(df_1, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('5 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                   theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_1_reduced <- df_1 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_1_reduced <- ggplot(df_1_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('5 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                   theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_1




```

```{r, echo=FALSE}
plot_1_reduced
```


$$~$$

## *Section II: 10 Independent Variables, Normally Distributed*

We have a survey with 10 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable is normally distributed.  The historical model of best fit has been determined to be 


\begin{align*}
logit(Y) &= -1.25 + 0.9x_1 - 0.85x_2 + 0.8x_3 - 0.75x_4 + 0.7x_5 \\ 
&\qquad - 0.65x_6 + 0.6x_7 - 0.55x_8 + 0.5x_9 - 0.45x_{10}
\end{align*}

$$~$$



```{r, historical misclassification distribution 2, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 1000




miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_2 <- data.frame(Historical_2_Historical = miss_vec)

```

```{r, simulation function 2, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_2 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 2, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_2 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_2[[paste0("Uninformative_2_Scenario_",ind)]] <- sim_func_2(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_2 <- as.data.frame(uninformative_2)

```

```{r, slight 2, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_2 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_2[[paste0("Slight_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_2 <- as.data.frame(slight_2)

```

```{r, extreme 2, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_2 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_2[[paste0("Extreme_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_2 <- as.data.frame(extreme_2)

```

```{r, summary 2, echo=FALSE, cache=TRUE}

df_2 <- tibble(historical_2, uninformative_2, slight_2, extreme_2) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_2_")
   

df_2$Scenario <- factor(df_2$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_2$Model <- factor(df_2$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_2 <- ggplot(df_2, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +
               theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_2_reduced <- df_2 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")


plot_2_reduced <- ggplot(df_2_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +
               theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_2


```

```{r, hypothesis tests of equivalence 2, echo=FALSE, eval=FALSE}

data_data <- df_2

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests2 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests2, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```

```{r, echo=FALSE}
plot_2_reduced
```


$$~$$
\newpage

## *Section III: 20 Independent Variables, Normally Distributed*

We have a survey with 20 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable is normally distributed.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= -2 + 1.2x_1 - 1.15x_2 + 1.1x_3 - 1.05x_4 + 1x_5 - 0.95x_6 + 0.9x_7 - 0.85x_8 \\ 
&\qquad+ 0.8x_9 - 0.75x_{10} + 0.7x_{11} - 0.65x_{12} + 0.6x_{13} - 0.55x_{14} + 0.5x_{15} \\ 
&\qquad - 0.45x_{16} + 0.4x_{17} - 0.35x_{18} + 0.3x_{19} - 0.25x_{20}
\end{align*}

$$~$$



```{r, historical misclassification distribution 3, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){
   
n <- 20

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_3 <- data.frame(Historical_3_Historical = miss_vec)

```

```{r, simulation function 3, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_3 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 20                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)                                      #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-2 + 1.2*data_pert$x1 - 1.15*data_pert$x2 + 1.1*data_pert$x3 - 
1.05*data_pert$x4 + 1*data_pert$x5 - 0.95*data_pert$x6 + 0.9*data_pert$x7 - 
0.85*data_pert$x8 + 0.8*data_pert$x9 - 0.75*data_pert$x10 + 0.7*data_pert$x11 - 
0.65*data_pert$x12 + 0.6*data_pert$x13 - 0.55*data_pert$x14 + 0.5*data_pert$x15 - 
0.45*data_pert$x16 + 0.4*data_pert$x17 - 0.35*data_pert$x18 + 0.3*data_pert$x19 - 
0.25*data_pert$x20)                                                           ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_pert, family = "binomial")                                ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 3, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_3 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_3[[paste0("Uninformative_3_Scenario_",ind)]] <- sim_func_3(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_3 <- as.data.frame(uninformative_3)

```

```{r, slight 3, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_3 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_3[[paste0("Slight_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_3 <- as.data.frame(slight_3)

```

```{r, extreme 3, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_3 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_3[[paste0("Extreme_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_3 <- as.data.frame(extreme_3)

```

```{r, summary 3, echo=FALSE, cache=TRUE}

df_3 <- tibble(historical_3, uninformative_3, slight_3, extreme_3) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_3_")

df_3$Scenario <- factor(df_3$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_3$Model <- factor(df_3$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_3 <- ggplot(df_3, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('20 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_3_reduced <- df_3 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")


plot_3_reduced <- ggplot(df_3_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('20 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_3

```

```{r, echo=FALSE}
plot_3_reduced
```


\newpage

## *Section IV: 10 Independent Variables, Triangular Distribution*

We have a survey with 10 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable follows a triangular distribution.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= -1.25 + 0.9x_1 - 0.85x_2 + 0.8x_3 - 0.75x_4 + 0.7x_5 \\ 
& \qquad - 0.65x_6 + 0.6x_7 - 0.55x_8 + 0.5x_9 - 0.45x_{10}
\end{align*}

$$~$$



```{r, historical misclassification distribution 4, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_2)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_4 <- data.frame(Historical_4_Historical = miss_vec)

```

```{r, simulation function 4, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_4 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 4, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
uninformative_4 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_4[[paste0("Uninformative_4_Scenario_",ind)]] <- sim_func_4(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_4 <- as.data.frame(uninformative_4)

```

```{r, slight 4, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
slight_4 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_4[[paste0("Slight_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_4 <- as.data.frame(slight_4)

```

```{r, extreme 4, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
extreme_4 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_4[[paste0("Extreme_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_4 <- as.data.frame(extreme_4)

```

```{r, summary 4, echo=FALSE, cache=TRUE}

df_4 <- tibble(historical_4, uninformative_4, slight_4, extreme_4) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_4_")

df_4$Scenario <- factor(df_4$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_4$Model <- factor(df_4$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_4 <- ggplot(df_4, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Triangular Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_4_reduced <- df_4 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")


plot_4_reduced <- ggplot(df_4_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Triangular Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_4


```

```{r, hypothesis tests of equivalence 4, echo=FALSE, eval=FALSE}

data_data <- df_4

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests4 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests4, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```

```{r, echo=FALSE}
plot_4_reduced
```



\newpage

## *Section V: 10 Independent Variables, Near Uniform Distribution*

We have a survey with 10 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable follows a near uniform distribution.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= 0.8x_1 - 0.75x_2 + 0.7x_3 - 0.65x_4 + 0.6x_5 \\ 
& \qquad - 0.55x_6 + 0.5x_7 - 0.45x_8 + 0.4x_9 - 0.35x_{10}
\end{align*}

$$~$$



```{r, historical misclassification distribution 5, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 1000



miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

x <- rmultinom(n=n, size=size, prob=probs_3)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_5 <- data.frame(Historical_5_Historical = miss_vec)    ##############

```

```{r, simulation function 5, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_5 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 5, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
uninformative_5 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_5[[paste0("Uninformative_5_Scenario_",ind)]] <- sim_func_5(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_5 <- as.data.frame(uninformative_5)

```

```{r, slight 5, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
slight_5 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_5[[paste0("Slight_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_5 <- as.data.frame(slight_5)

```

```{r, extreme 5, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
extreme_5 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_5[[paste0("Extreme_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_5 <- as.data.frame(extreme_5)

```

```{r, summary 5, echo=FALSE, cache=TRUE}

df_5 <- tibble(historical_5, uninformative_5, slight_5, extreme_5) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_5_")

df_5$Scenario <- factor(df_5$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_5$Model <- factor(df_5$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_5 <- ggplot(df_5, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Near Uniform Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_5_reduced <- df_5 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_5_reduced <- ggplot(df_5_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Near Uniform Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_5


```

```{r, hypothesis tests of equivalence 5, echo=FALSE, eval=FALSE}


data_data <- df_5

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests5 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests5, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```

```{r, echo=FALSE}
plot_5_reduced
```



\newpage

## *Section VI: 10 Independent Variables, Bi-modal Distribution*

We have a survey with 10 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable follows a bi-modal distribution.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= -1 + 0.8x_1 - 0.75x_2 + 0.7x_3 - 0.65x_4 + 0.6x_5 \\ 
& \qquad - 0.55x_6 + 0.5x_7 - 0.45x_8 + 0.4x_9 - 0.35x_{10}
\end{align*}

$$~$$



```{r, historical misclassification distribution 6, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

x <- rmultinom(n=n, size=size, prob=probs_4)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_6 <- data.frame(Historical_6_Historical = miss_vec)    ##############

```

```{r, simulation function 6, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_6 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 6, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
uninformative_6 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_6[[paste0("Uninformative_6_Scenario_",ind)]] <- sim_func_6(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_6 <- as.data.frame(uninformative_6)

```

```{r, slight 6, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
slight_6 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_6[[paste0("Slight_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_6 <- as.data.frame(slight_6)

```

```{r, extreme 6, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
extreme_6 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_6[[paste0("Extreme_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_6 <- as.data.frame(extreme_6)

```

```{r, summary 6, echo=FALSE, cache=TRUE}

df_6 <- tibble(historical_6, uninformative_6, slight_6, extreme_6) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_6_")

df_6$Scenario <- factor(df_6$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_6$Model <- factor(df_6$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_6 <- ggplot(df_6, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Bi-modal Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_6_reduced <- df_6 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_6_reduced <- ggplot(df_6_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Bi-modal Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_6


```

```{r, hypothesis tests of equivalence 6, echo=FALSE, eval=FALSE}

data_data <- df_6

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests6 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests6, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```

```{r, echo=FALSE}
plot_6_reduced
```


\newpage

## *Section VII: 10 Independent Variables, Right-Skewed Distribution*

We have a survey with 10 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable follows a right-skewed distribution.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= -1 + 0.8x_1 - 0.75x_2 + 0.7x_3 - 0.65x_4 + 0.6x_5 \\ 
& \qquad - 0.55x_6 + 0.5x_7 - 0.45x_8 + 0.4x_9 - 0.35x_{10}
\end{align*}

$$~$$


```{r, historical misclassification distribution 7, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_5)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_7 <- data.frame(Historical_7_Historical = miss_vec)    ##############

```

```{r, simulation function 7, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_7 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 7, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
uninformative_7 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_7[[paste0("Uninformative_7_Scenario_",ind)]] <- sim_func_7(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_7 <- as.data.frame(uninformative_7)

```

```{r, slight 7, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
slight_7 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_7[[paste0("Slight_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_7 <- as.data.frame(slight_7)

```

```{r, extreme 7, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
extreme_7 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_7[[paste0("Extreme_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_7 <- as.data.frame(extreme_7)

```

```{r, summary 7, echo=FALSE, cache=TRUE}

df_7 <- tibble(historical_7, uninformative_7, slight_7, extreme_7) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_7_")

df_7$Scenario <- factor(df_7$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_7$Model <- factor(df_7$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_7 <- ggplot(df_7, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Right-Skewed Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_7_reduced <- df_7 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_7_reduced <- ggplot(df_7_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Right-Skewed Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_7


```

```{r, hypothesis tests of equivalence 7, echo=FALSE, eval=FALSE}

data_data <- df_7

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests7 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests7, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```

```{r, echo=FALSE}
plot_7_reduced
```


\newpage

## *Section VIII: 10 Independent Variables, Left-Skewed Distribution*

We have a survey with 10 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (identical ordinal scales).  Each independent variable follows a left-skewed distribution.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= -1 + 0.8x_1 - 0.75x_2 + 0.7x_3 - 0.65x_4 + 0.6x_5 \\ 
& \qquad - 0.55x_6 + 0.5x_7 - 0.45x_8 + 0.4x_9 - 0.35x_{10}
\end{align*}

$$~$$


```{r, historical misclassification distribution 8, echo=FALSE, cache=TRUE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

x <- rmultinom(n=n, size=size, prob=probs_6)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_8 <- data.frame(Historical_8_Historical = miss_vec)    ##############

```

```{r, simulation function 8, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_8 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 8, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

# initialize list for output
uninformative_8 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_8[[paste0("Uninformative_8_Scenario_",ind)]] <- sim_func_8(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_6, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_8 <- as.data.frame(uninformative_8)

```

```{r, slight 8, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

# initialize list for output
slight_8 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_8[[paste0("Slight_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_6, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_8 <- as.data.frame(slight_8)

```

```{r, extreme 8, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

# initialize list for output
extreme_8 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_8[[paste0("Extreme_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_6, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_8 <- as.data.frame(extreme_8)

```

```{r, summary 8, echo=FALSE, cache=TRUE}

df_8 <- tibble(historical_8, uninformative_8, slight_8, extreme_8) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_8_")

df_8$Scenario <- factor(df_8$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_8$Model <- factor(df_8$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_8 <- ggplot(df_8, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Left-Skewed Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_8_reduced <- df_8 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_8_reduced <- ggplot(df_8_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Left-Skewed Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_8


```

```{r, echo=FALSE}
plot_8_reduced
```

\newpage

## *Section IX: 12 Independent Variables, Mixed Distributions*

We have a survey with 12 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (mixed ordinal scales).  Each independent variable follows one of six provided distributions.  The historical model of best fit has been determined to be 

\begin{align*}
logit(Y) &= -1 + 0.6x_1 - 0.55x_2 + 0.6x_3 - 0.55x_4 + 0.6x_5 - 0.55x_6 \\ 
& \qquad + 0.6x_7 - 0.55x_8 + 0.6x_9 - 0.55x_{10} + 0.6x_{11} - 0.55x_{12}
\end{align*}

$$~$$



```{r, historical misclassification distribution 9, echo=FALSE, cache=TRUE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){

size <- nobs
n <- 12


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_9 <- data.frame(Historical_9_Historical = miss_vec)    ##############

```

```{r, simulation function 9, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_9 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 12
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.6*data_pert$x1 - 0.55*data_pert$x2 + 0.6*data_pert$x3 - 
0.55*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.6*data_pert$x7 - 
0.55*data_pert$x8 + 0.6*data_pert$x9 - 0.55*data_pert$x10 + 
0.6*data_pert$x11 - 0.55*data_pert$x12)                       

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 9, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_9 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_9[[paste0("Uninformative_9_Scenario_",ind)]] <- sim_func_9(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_9 <- as.data.frame(uninformative_9)

```

```{r, slight 9, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_9 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_9[[paste0("Slight_9_Scenario_",ind)]] <- sim_func_9(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 1000)
   ind <- ind+1
}
slight_9 <- as.data.frame(slight_9)

```

```{r, extreme 9, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_9 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_9[[paste0("Extreme_9_Scenario_",ind)]] <- sim_func_9(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_9 <- as.data.frame(extreme_9)

```

```{r, summary 9, echo=FALSE, cache=TRUE}

df_9 <- tibble(historical_9, uninformative_9, slight_9, extreme_9) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_9_")

df_9$Scenario <- factor(df_9$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_9$Model <- factor(df_9$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_9 <- ggplot(df_9, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('12 Independent Variables, Mixed Distributions') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_9_reduced <- df_9 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")



plot_9_reduced <- ggplot(df_9_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('12 Independent Variables, Mixed Distributions, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = "Boxplots showing misclassification distributions for 1000 simulations of each unique scenario and replacement \n model (perturbation) type.")


plot_9


```

```{r, hypothesis tests of equivalence 9, echo=FALSE, eval=FALSE}

data_data <- df_9

# Nothing below this point has been updated to _9 from _8


################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests8 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests8, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```

```{r, echo=FALSE}
plot_9_reduced
```




\newpage

## *Section X: 30 Independent Variables, Mixed Distributions*

We have a survey with 30 questions and a classification for a respondent in one of two categories (eg, male/female).  Probabilities are determined using an additive binary logistic regression model.  Each question requires an ordinal response on a scale with one being the lowest value and five being the highest value (mixed ordinal scales).  Each independent variable follows one of six provided distributions.  The historical model of best fit has been determined to be 


\begin{align*}
logit(Y) &= -1.5 + 0.66x_1 - 0.64x_2 + 0.62x_3 - 0.6x_4 + 0.58x_5 - 0.56x_6 \\ 
& \qquad + 0.54x_7 - 0.52x_8 + 0.5x_9 - 0.48x_{10} + 0.46x_{11} - 0.44x_{12} \\
& \qquad + 0.42x_{13} - 0.4x_{14} + 0.38x_{15} - 0.36x_{16} + 0.34x_{17} - 0.32x_{18} \\
& \qquad + 0.3x_{19} - 0.28x_{20} + 0.26x_{21} - 0.24x_{22} + 0.22x_{23} - 0.2x_{24} \\
& \qquad + 0.18x_{25} - 0.16x_{26} + 0.14x_{27} - 0.12x_{28} + 0.1x_{29} - 0.08x_{30}
\end{align*}

$$~$$

```{r, historical misclassification distribution 10, echo=FALSE, cache=TRUE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){

size <- nobs
n <- 30


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=5, size=size, prob=probs_1)
mix_2 <- rmultinom(n=5, size=size, prob=probs_2)
mix_3 <- rmultinom(n=5, size=size, prob=probs_3)
mix_4 <- rmultinom(n=5, size=size, prob=probs_4)
mix_5 <- rmultinom(n=5, size=size, prob=probs_5)
mix_6 <- rmultinom(n=5, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1.5 + 0.66*data_long$x1 - 0.64*data_long$x2 + 0.62*data_long$x3 - 
0.6*data_long$x4 + 0.58*data_long$x5 - 0.56*data_long$x6 + 0.54*data_long$x7 - 
0.52*data_long$x8 + 0.5*data_long$x9 - 0.48*data_long$x10 + 0.46*data_long$x11 - 
0.44*data_long$x12 + 0.42*data_long$x13 - 0.4*data_long$x14 + 0.38*data_long$x15 - 
0.36*data_long$x16 + 0.34*data_long$x17 - 0.32*data_long$x18 + 0.3*data_long$x19 - 
0.28*data_long$x20 + 0.26*data_long$x21 - 0.24*data_long$x22 + 0.22*data_long$x23 - 
0.2*data_long$x24 + 0.18*data_long$x25 - 0.16*data_long$x26 + 0.14*data_long$x27 - 
0.12*data_long$x28 + 0.1*data_long$x29 - 0.08*data_long$x30)          #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
              x21+x22+x23+x24+x25+x26+x27+x28+x29+x30, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_10 <- data.frame(Historical_10_Historical = miss_vec)    ##############

```

```{r, simulation function 10, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_10 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 30
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=5, size=size, prob=probs_1)
mix_2 <- rmultinom(n=5, size=size, prob=probs_2)
mix_3 <- rmultinom(n=5, size=size, prob=probs_3)
mix_4 <- rmultinom(n=5, size=size, prob=probs_4)
mix_5 <- rmultinom(n=5, size=size, prob=probs_5)
mix_6 <- rmultinom(n=5, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.5 + 0.66*data_long$x1 - 0.64*data_long$x2 + 0.62*data_long$x3 - 
0.6*data_long$x4 + 0.58*data_long$x5 - 0.56*data_long$x6 + 0.54*data_long$x7 - 
0.52*data_long$x8 + 0.5*data_long$x9 - 0.48*data_long$x10 + 0.46*data_long$x11 - 
0.44*data_long$x12 + 0.42*data_long$x13 - 0.4*data_long$x14 + 0.38*data_long$x15 - 
0.36*data_long$x16 + 0.34*data_long$x17 - 0.32*data_long$x18 + 0.3*data_long$x19 - 
0.28*data_long$x20 + 0.26*data_long$x21 - 0.24*data_long$x22 + 0.22*data_long$x23 - 
0.2*data_long$x24 + 0.18*data_long$x25 - 0.16*data_long$x26 + 0.14*data_long$x27 - 
0.12*data_long$x28 + 0.1*data_long$x29 - 0.08*data_long$x30)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.5 + 0.66*data_pert$x1 - 0.64*data_pert$x2 + 0.62*data_pert$x3 - 
0.6*data_pert$x4 + 0.58*data_pert$x5 - 0.56*data_pert$x6 + 0.54*data_pert$x7 - 
0.52*data_pert$x8 + 0.5*data_pert$x9 - 0.48*data_pert$x10 + 0.46*data_pert$x11 - 
0.44*data_pert$x12 + 0.42*data_pert$x13 - 0.4*data_pert$x14 + 0.38*data_pert$x15 - 
0.36*data_pert$x16 + 0.34*data_pert$x17 - 0.32*data_pert$x18 + 0.3*data_pert$x19 - 
0.28*data_pert$x20 + 0.26*data_pert$x21 - 0.24*data_pert$x22 + 0.22*data_pert$x23 - 
0.2*data_pert$x24 + 0.18*data_pert$x25 - 0.16*data_pert$x26 + 0.14*data_pert$x27 - 
0.12*data_pert$x28 + 0.1*data_pert$x29 - 0.08*data_pert$x30)                     

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
              x21+x22+x23+x24+x25+x26+x27+x28+x29+x30, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 10, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_10 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_10[[paste0("Uninformative_10_Scenario_",ind)]] <- sim_func_10(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_10 <- as.data.frame(uninformative_10)

```

```{r, slight 10, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_10 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_10[[paste0("Slight_10_Scenario_",ind)]] <- sim_func_10(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 1000)
   ind <- ind+1
}
slight_10 <- as.data.frame(slight_10)

```

```{r, extreme 10, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_10 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_10[[paste0("Extreme_10_Scenario_",ind)]] <- sim_func_10(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_10 <- as.data.frame(extreme_10)

```

```{r, summary 10, echo=FALSE, cache=TRUE}

df_10 <- tibble(historical_10, uninformative_10, slight_10, extreme_10) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_10_")

df_10$Scenario <- factor(df_10$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_10$Model <- factor(df_10$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_10 <- ggplot(df_10, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('30 Independent Variables, Mixed Distributions') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_10_reduced <- df_10 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")



plot_10_reduced <- ggplot(df_10_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('30 Independent Variables, Mixed Distributions, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = "Boxplots showing misclassification distributions for 1000 simulations of each unique scenario and replacement \n model (perturbation) type.")


plot_10


```

```{r, echo=FALSE}
plot_10_reduced
```



\newpage


## *Section XI: Common Problems with Poor Models*


All of the models used in this study had coefficients chosen so that logit(Y) had a range of no more than roughly (-8,8) and centered at about zero, while making all coefficients statistically significant.  The reason for this was to remove the occurrence of models being fit with probabilities equaling zero or one while attempting to have a sufficiently wide range.  

When the choice of coefficients results in logit(Y) being constrained into a very small range, or an arbitrarily large intercept is incorporated into an otherwise sufficient model, the following results will occur.  The model will be unable to sufficiently dichotomize logit(Y) and there will appear to be no effect of any perturbation scenario whatsoever. 


\begin{align*}
logit(Y) &= -1 + 0.096x_1 - 0.094x_2 + 0.092x_3 - 0.09x_4 + 0.088x_5 - 0.086x_6 \\ 
& \qquad + 0.084x_7 - 0.082x_8 + 0.08x_9 - 0.078x_{10} + 0.076x_{11} - 0.074x_{12} \\
& \qquad + 0.072x_{13} - 0.07x_{14} + 0.068x_{15} - 0.066x_{16} + 0.064x_{17} - 0.062x_{18} \\
& \qquad + 0.06x_{19} - 0.058x_{20} + 0.056x_{21} - 0.054x_{22} + 0.052x_{23} - 0.05x_{24} \\
& \qquad + 0.048x_{25} - 0.046x_{26} + 0.044x_{27} - 0.042x_{28} + 0.04x_{29} - 0.038x_{30}
\end{align*}

$$~$$

```{r, historical misclassification distribution 10e, echo=FALSE, cache=TRUE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){

size <- nobs
n <- 30


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=5, size=size, prob=probs_1)
mix_2 <- rmultinom(n=5, size=size, prob=probs_2)
mix_3 <- rmultinom(n=5, size=size, prob=probs_3)
mix_4 <- rmultinom(n=5, size=size, prob=probs_4)
mix_5 <- rmultinom(n=5, size=size, prob=probs_5)
mix_6 <- rmultinom(n=5, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1 + 0.096*data_long$x1 - 0.094*data_long$x2 + 0.092*data_long$x3 - 
0.09*data_long$x4 + 0.088*data_long$x5 - 0.086*data_long$x6 + 0.084*data_long$x7 - 
0.082*data_long$x8 + 0.08*data_long$x9 - 0.078*data_long$x10 + 0.076*data_long$x11 - 
0.074*data_long$x12 + 0.072*data_long$x13 - 0.07*data_long$x14 + 0.068*data_long$x15 - 
0.066*data_long$x16 + 0.064*data_long$x17 - 0.062*data_long$x18 + 0.06*data_long$x19 - 
0.058*data_long$x20 + 0.056*data_long$x21 - 0.054*data_long$x22 + 0.052*data_long$x23 - 
0.05*data_long$x24 + 0.048*data_long$x25 - 0.046*data_long$x26 + 0.044*data_long$x27 - 
0.042*data_long$x28 + 0.04*data_long$x29 - 0.038*data_long$x30)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
              x21+x22+x23+x24+x25+x26+x27+x28+x29+x30, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_10e <- data.frame(Historical_10_Historical = miss_vec)    ##############

```

```{r, simulation function 10e, echo=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_10e <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 30
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=5, size=size, prob=probs_1)
mix_2 <- rmultinom(n=5, size=size, prob=probs_2)
mix_3 <- rmultinom(n=5, size=size, prob=probs_3)
mix_4 <- rmultinom(n=5, size=size, prob=probs_4)
mix_5 <- rmultinom(n=5, size=size, prob=probs_5)
mix_6 <- rmultinom(n=5, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.096*data_long$x1 - 0.094*data_long$x2 + 0.092*data_long$x3 - 
0.09*data_long$x4 + 0.088*data_long$x5 - 0.086*data_long$x6 + 0.084*data_long$x7 - 
0.082*data_long$x8 + 0.08*data_long$x9 - 0.078*data_long$x10 + 0.076*data_long$x11 - 
0.074*data_long$x12 + 0.072*data_long$x13 - 0.07*data_long$x14 + 0.068*data_long$x15 - 
0.066*data_long$x16 + 0.064*data_long$x17 - 0.062*data_long$x18 + 0.06*data_long$x19 - 
0.058*data_long$x20 + 0.056*data_long$x21 - 0.054*data_long$x22 + 0.052*data_long$x23 - 
0.05*data_long$x24 + 0.048*data_long$x25 - 0.046*data_long$x26 + 0.044*data_long$x27 - 
0.042*data_long$x28 + 0.04*data_long$x29 - 0.038*data_long$x30) 

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.096*data_pert$x1 - 0.094*data_pert$x2 + 0.092*data_pert$x3 - 
0.09*data_pert$x4 + 0.088*data_pert$x5 - 0.086*data_pert$x6 + 0.084*data_pert$x7 - 
0.082*data_pert$x8 + 0.08*data_pert$x9 - 0.078*data_pert$x10 + 0.076*data_pert$x11 - 
0.074*data_pert$x12 + 0.072*data_pert$x13 - 0.07*data_pert$x14 + 0.068*data_pert$x15 - 
0.066*data_pert$x16 + 0.064*data_pert$x17 - 0.062*data_pert$x18 + 0.06*data_pert$x19 - 
0.058*data_pert$x20 + 0.056*data_pert$x21 - 0.054*data_pert$x22 + 0.052*data_pert$x23 - 
0.05*data_pert$x24 + 0.048*data_pert$x25 - 0.046*data_pert$x26 + 0.044*data_pert$x27 - 
0.042*data_pert$x28 + 0.04*data_pert$x29 - 0.038*data_pert$x30)                      

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
              x21+x22+x23+x24+x25+x26+x27+x28+x29+x30, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 10e, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_10e <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_10e[[paste0("Uninformative_10_Scenario_",ind)]] <- sim_func_10e(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_10e <- as.data.frame(uninformative_10e)

```

```{r, slight 10e, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_10e <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_10e[[paste0("Slight_10_Scenario_",ind)]] <- sim_func_10e(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 1000)
   ind <- ind+1
}
slight_10e <- as.data.frame(slight_10e)

```

```{r, extreme 10e, echo=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_10e <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_10e[[paste0("Extreme_10_Scenario_",ind)]] <- sim_func_10e(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_10e <- as.data.frame(extreme_10e)

```

```{r, summary 10e, echo=FALSE, cache=TRUE}

df_10e <- tibble(historical_10e, uninformative_10e, slight_10e, extreme_10e) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_10_")

df_10e$Scenario <- factor(df_10e$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_10e$Model <- factor(df_10e$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_10e <- ggplot(df_10e, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('30 Independent Variables, Mixed Distributions') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_10e


```



\newpage

# *Hypothesis Tests of Equivalence*


Consider the distribution of logit(Y) when all independent variables are normally distributed.  In this case, the distribution of logit(Y) follows naturally.  Now assume that 25% of observations are selected at random and perturbed in a positive direction using, say, a slight conditional replacement distribution.  This will have the effect of biasing the distribution of logit(Y) in the positive direction towards the probability of success with an increased misclassification rate.  When the previous scenario is repeated, but in the negative direction, the distribution of logit(Y) will follow suit with the same increase in the misclassification rate.

Although the misclassification rates are the result of the same distribution perturbed in different directions, the value of the misclassification rate will be the same.  If repeated a sufficient number of times, each of the respective misclassification distributions will be equivalent.

In an attempt to prove this equivalence, both Kolmogorov-Smirnov hypothesis tests of distributional equivalence, and large sample t-tests of difference of means, were performed between equivalent perturbation scenarios.  Unfortunately, results were inconsistent.  Tables 3, 4, 5, and 6 show results for both KS-tests and t-tests for two situations.  The first is a model with five normally distributed independent ordinal variables.  The second is a model with thirty independent ordinal variables using all six distributions created for this study.

In tables 3 and 4, many of the distributions have p-values small enough to be reported as equal to zero, while other distributions have p-values near or at one.  Tables 5 and 6 show an increase in consistency with p-values above a computed value of zero.  This is consistent with the hypothesis tests performed after Section I.  As the complexity of the model increases, the hypothesis test results tend to stabilize, but only to a point.  Some of the most consistent results occurred in Section IX.  



\begin{table}[!ht]
\centering
\caption{1000 Observations and 1000 Simulations: Kolmogorov-Smirnov 
hypothesis test of difference of distributions for equivalent perturbation scenarios - Five independent, normally distributed ordinal variables - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.048 (0.2) & 0.124 (0) & 0.138 (0) \\ 
  2 vs 9 & 0.043 (0.314) & 0.116 (0) & 0.105 (0) \\ 
  3 vs 12 & 0.074 (0.008) & 0.117 (0) & 0.078 (0.005) \\ 
  4 vs 14 & 0.112 (0) & 0.138 (0) & 0.087 (0.001) \\ 
  7 vs 10 & 0.02 (0.988) & 0.033 (0.648) & 0.029 (0.794) \\ 
  8 vs 13 & 0.023 (0.954) & 0.023 (0.954) & 0.011 (1) \\ 
   \hline
\end{tabular}
\end{table}




\begin{table}[!ht]
\centering
\caption{1000 Observations and 1000 Simulations: Large sample hypothesis tests of  equivalent sample mean for equivalent perturbation scenarios - Five independent, normally distributed ordinal variables - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 1.189 (0.234) & 5.539 (0) & 6.207 (0) \\ 
  2 vs 9 & 0.885 (0.376) & 5.059 (0) & 5.219 (0) \\ 
  3 vs 12 & 3.28 (0.001) & 6.112 (0) & 3.524 (0) \\ 
  4 vs 14 & 5.006 (0) & 6.653 (0) & 3.986 (0) \\ 
  7 vs 10 & -0.263 (0.793) & 0.785 (0.432) & 0.307 (0.759) \\ 
  8 vs 13 & -0.003 (0.998) & 0.091 (0.928) & 0.052 (0.959) \\ 
   \hline
\end{tabular}
\end{table}




\begin{table}[!ht]
\centering
\caption{1000 Observations and 1000 Simulations: Kolmogorov-Smirnov 
hypothesis test of difference of distributions for equivalent perturbation scenarios - Thirty independent ordinal variables with mixed distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.052 (0.134) & 0.046 (0.241) & 0.068 (0.02) \\ 
  2 vs 9 & 0.06 (0.055) & 0.063 (0.038) & 0.058 (0.069) \\ 
  3 vs 12 & 0.036 (0.536) & 0.032 (0.685) & 0.04 (0.4) \\ 
  4 vs 14 & 0.039 (0.432) & 0.029 (0.794) & 0.023 (0.954) \\ 
  7 vs 10 & 0.017 (0.999) & 0.056 (0.087) & 0.027 (0.859) \\ 
  8 vs 13 & 0.022 (0.969) & 0.035 (0.573) & 0.038 (0.466) \\ 
   \hline
\end{tabular}
\end{table}




\begin{table}[!ht]
\centering
\caption{1000 Observations and 1000 Simulations: Large sample hypothesis tests of  equivalent sample mean for equivalent perturbation scenarios - Thirty independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 1.763 (0.078) & 1.774 (0.076) & 2.936 (0.003) \\ 
  2 vs 9 & 2.733 (0.006) & 3.131 (0.002) & 3.06 (0.002) \\ 
  3 vs 12 & 0.746 (0.455) & 1.634 (0.102) & 0.53 (0.596) \\ 
  4 vs 14 & 0.775 (0.438) & -0.535 (0.593) & -0.314 (0.754) \\ 
  7 vs 10 & 0.138 (0.891) & 1.877 (0.061) & 0.163 (0.871) \\ 
  8 vs 13 & -0.199 (0.843) & 0.064 (0.949) & -0.544 (0.586) \\ 
   \hline
\end{tabular}
\end{table}

$$~$$
\newpage
$$~$$
\newpage

The expectation is that as the number of observations increase, the variance will decrease, but this alone has been proven to be an insufficient explanation for the behavior seen in these simulations.  The logical explanation is that the combination of sample size, number of simulations, number of independent variables, and choice of variable coefficients is responsible for the behavior.  

In order to justify this based on the effects of the number of observations being simulated, $N_{obs},$ and the number of simulations being performed, $N_{sims},$ both were varied and applied to scenario IX using a factorial design.  $N_{obs}=\{200, 1000\}$ and $N_{sims}=\{100, 1000\}$ were used.  Note that when using 100 observations, the binary logistic regression models frequently fit with probabilities of zero and one.  Increasing this value to 200 prevented this from occurring.  

Tables 7 through 14 show that both an increase in the number of simulations, and an increase in the number of observations, improve the equivalence of the misclassification distributions.  


$$~$$

\begin{table}[!ht]
\centering
\caption{1000 Observations and 1000 Simulations:  Kolmogorov-Smirnov tests of distributional equivalence for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.024 (0.936) & 0.03 (0.759) & 0.026 (0.888) \\ 
  2 vs 9 & 0.037 (0.5) & 0.038 (0.466) & 0.05 (0.164) \\ 
  3 vs 12 & 0.023 (0.954) & 0.031 (0.723) & 0.032 (0.685) \\ 
  4 vs 14 & 0.034 (0.61) & 0.035 (0.573) & 0.028 (0.828) \\ 
  7 vs 10 & 0.038 (0.466) & 0.035 (0.573) & 0.025 (0.913) \\ 
  8 vs 13 & 0.04 (0.4) & 0.024 (0.936) & 0.035 (0.573) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.039 (0.969) & 0.03 (0.976) & -0.773 (0.44) \\ 
  2 vs 9 & 0.912 (0.362) & 0.543 (0.587) & 1.334 (0.182) \\ 
  3 vs 12 & -0.178 (0.859) & -0.988 (0.323) & -0.398 (0.69) \\ 
  4 vs 14 & 0.917 (0.359) & 1.314 (0.189) & -0.299 (0.765) \\ 
  7 vs 10 & -1.637 (0.102) & -1.23 (0.219) & -0.234 (0.815) \\ 
  8 vs 13 & -0.881 (0.379) & -0.449 (0.653) & 0.971 (0.332) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{1000 Observations and 100 Simulations:  Kolmogorov-Smirnov tests of distributional equivalence for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.07 (0.967) & 0.1 (0.699) & 0.09 (0.813) \\ 
  2 vs 9 & 0.09 (0.813) & 0.05 (1) & 0.09 (0.813) \\ 
  3 vs 12 & 0.05 (1) & 0.11 (0.581) & 0.1 (0.699) \\ 
  4 vs 14 & 0.11 (0.581) & 0.09 (0.813) & 0.11 (0.581) \\ 
  7 vs 10 & 0.14 (0.281) & 0.08 (0.906) & 0.15 (0.211) \\ 
  8 vs 13 & 0.15 (0.211) & 0.13 (0.367) & 0.13 (0.367) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.137 (0.891) & -0.1 (0.92) & -0.571 (0.568) \\ 
  2 vs 9 & -0.425 (0.671) & 0.478 (0.633) & 0.998 (0.318) \\ 
  3 vs 12 & -0.132 (0.895) & -0.962 (0.336) & -1.094 (0.274) \\ 
  4 vs 14 & 0.955 (0.339) & 1.177 (0.239) & -0.118 (0.906) \\ 
  7 vs 10 & -1.871 (0.061) & -0.552 (0.581) & -1.031 (0.303) \\ 
  8 vs 13 & -0.856 (0.392) & -1.632 (0.103) & 0.418 (0.676) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{200 Observations and 1000 Simulations:  Kolmogorov-Smirnov tests of distributional equivalence for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.021 (0.98) & 0.014 (1) & 0.035 (0.573) \\ 
  2 vs 9 & 0.036 (0.536) & 0.038 (0.466) & 0.022 (0.969) \\ 
  3 vs 12 & 0.027 (0.859) & 0.025 (0.913) & 0.023 (0.954) \\ 
  4 vs 14 & 0.032 (0.685) & 0.033 (0.648) & 0.02 (0.988) \\ 
  7 vs 10 & 0.035 (0.573) & 0.029 (0.794) & 0.031 (0.723) \\ 
  8 vs 13 & 0.015 (1) & 0.046 (0.241) & 0.031 (0.723) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.768 (0.443) & 0.004 (0.997) & 1.607 (0.108) \\ 
  2 vs 9 & 0.666 (0.505) & 0.494 (0.621) & -0.025 (0.98) \\ 
  3 vs 12 & -0.07 (0.944) & 0.793 (0.428) & 0.536 (0.592) \\ 
  4 vs 14 & 0.075 (0.94) & -1.156 (0.248) & 0.127 (0.899) \\ 
  7 vs 10 & -0.614 (0.539) & -0.722 (0.47) & 0.311 (0.756) \\ 
  8 vs 13 & -0.152 (0.879) & 1.752 (0.08) & 0.615 (0.539) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{200 Observations and 100 Simulations:  Kolmogorov-Smirnov tests of distributional equivalence for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & 0.07 (0.967) & 0.08 (0.906) & 0.07 (0.967) \\ 
  2 vs 9 & 0.16 (0.155) & 0.12 (0.468) & 0.17 (0.111) \\ 
  3 vs 12 & 0.13 (0.367) & 0.07 (0.967) & 0.16 (0.155) \\ 
  4 vs 14 & 0.14 (0.281) & 0.08 (0.906) & 0.05 (1) \\ 
  7 vs 10 & 0.19 (0.054) & 0.12 (0.468) & 0.09 (0.813) \\ 
  8 vs 13 & 0.09 (0.813) & 0.15 (0.211) & 0.11 (0.581) \\ 
   \hline
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\caption{200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Twelve independent ordinal variables with mixeded distributions - Test statistic (P-value).} 
\begin{tabular}{llll}
  \hline
Scenario & Slight & Uninformative & Extreme \\ 
  \hline
1 vs 5 & -0.771 (0.441) & -0.083 (0.934) & -0.795 (0.427) \\ 
  2 vs 9 & -0.904 (0.366) & -1.446 (0.148) & -1.581 (0.114) \\ 
  3 vs 12 & -1.925 (0.054) & 0.188 (0.851) & -2.116 (0.034) \\ 
  4 vs 14 & -1.349 (0.177) & 0.081 (0.935) & 0.086 (0.932) \\ 
  7 vs 10 & -2.418 (0.016) & 0.154 (0.877) & -0.724 (0.469) \\ 
  8 vs 13 & -0.942 (0.346) & 0.152 (0.88) & 0.664 (0.507) \\ 
   \hline
\end{tabular}
\end{table}



\newpage
$$~$$
\newpage
$$~$$
\newpage



# *Discussion*

In sections I through VI, the distributions of the independent variables are symmetrical.  As a result, several of the perturbation scenarios are equivalent.  These equivalencies are in: scenario 1 and scenario 5, scenario 2 and scenario 9, scenario 3 and scenario 12, scenario 4 and scenario 14, scenario 7 and scenario 10, scenario 8 and scenario 13.  Hypothesis tests of statistical significance confirm these equivalencies but with the caveats mentioned in section XI.

Sections VII and VIII use a non-symmetrical distribution for the independent variables, and sections IX and X use all pre-defined distributions.  Hypothesis tests of statistical significance confirm that these perturbation scenarios are also equivalent, again also with caveats.  In sections VII and VIII, a highly skewed distribution for the independent variables would be required for the perturbation scenarios to be statistically non-equivalent.  For example, scenarios 1 and 5 are equivalent, but in opposite perturbation directions.  With the skewed distribution used in sections VII and VIII, it can be seen that the difference between slight, uninformative, and extreme perturbations within scenarios is clearly influenced. 

For example, consider scenarios 1 and 5 in sections VII and VIII.  The difference between the variance within scenarios 1 and 5 is due to the skewed distribution of the independent variables.  Since sections VII and VIII are opposites in that the former uses only right-skewed independent variables while the latter uses only left-skewed independent variables, the difference is reversed and symmetrically equivalent.

In sections I, II, and III, the independent variables are normally distributed.  It can be seen that as the number of independent variables increase, the historical misclassification distributions decrease.  In other words, the correct classification rate for the binary logistic regression model increases.  As can be seen most clearly in scenarios 11 in each section, the misclassification rate increases as the number of independent variables increase.  Also, the variance among the slight, uninformative, and extreme misclassification distributions increases as the number of independent variables increases.  This can be seen most clearly in scenarios 4 between sections I, II, and III.

Sections IV, V, and VI use a triangular, near uniform, and bi-modal distribution, respectively, for the independent variables.  The interquartile range of the historical misclassification rate distributions in each of these sections is between 15% and 20%.  It appears that the variance among the slight, uninformative, and extreme misclassification distributions within scenarios increases slightly as the independent model variables invert, viz., move from a triangular distribution to a bi-modal distribution.

Sections IX and X incorporate all six pre-defined distributions.  The only difference is that section IX has two independent variables from each distribution whereas section X has five independent variables from each distribution.  Both of these sections have an interquartile range for the historical misclassification rate distributions between 15% and 20%, but with the larger model performing slightly better.  The larger model also has lower misclassification rate distributions for every scenario, as well as smaller variance among the slight, uninformative, and extreme misclassification distributions within scenarios.  This indicates that in general, the more information gathered, the lower the misclassification rate in every falsification scenario.  
 
The R-SGR replacement process can most easily be viewed as a method of weighting the data using a beta probability distribution.  Under the context of data falsification, it can be seen in each of the previous sections that the misclassification rate always increases significantly when any data falsification is present.  In the worst case scenario, the correct classification rate is no better than the flip of a fair coin.  When the falsification is more heavily positive than negative, then the classification is biased positive.  The contrary is also true. It is also clear that as the scenarios widen, viz., the falsification increases in both directions, the corresponding increase in variance can be seen among the slight, uninformative, and extreme misclassification distributions within scenarios.



\newpage

# *References*

$$~$$

  Luigi Lombardi and Massimiliano Pastore (2014). sgr: A Package for Simulating 
  Conditional Fake Ordinal Data. The R Journal, 6(1), 164-177. URL
  http://journal.r-project.org/archive/2014-1/lombardi-pastore.pdf.
  
  Pastore, Massimiliano, et al. "Empirical Scenarios of Fake Data Analysis: The Sample 
  Generation by Replacement (Sgr) Approach." Frontiers in Psychology, vol. 8, 2017, 
  doi:10.3389/fpsyg.2017.00482. 
  
  Morris, T. P., White, I. R., & Crowther, M. J. (2019). Using simulation studies to 
  evaluate statistical methods. Statistics in Medicine, 38(11), 2074-2102. 
  https://doi.org/10.1002/sim.8086
  
  Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 
  4(43), 1686, https://doi.org/10.21105/joss.01686
  
  David B. Dahl, David Scott, Charles Roosen, Arni Magnusson and Jonathan Swinton (2019). 
  xtable: Export Tables to LaTeX or HTML. R package version 1.8-4. 
  https://CRAN.R-project.org/package=xtable
  
  R Core Team (2020). R: A language and environment for statistical computing. 
  R Foundation for Statistical Computing, Vienna, Austria.
  URL https://www.R-project.org/.
  
  
  
  
  
  
  
  
  
  

\newpage

# *Appendix*

The following code was used for part 1, section I of this paper.  The full code and RMarkdown document are available for download on GitHub via the following link:  

**https://github.com/mfulginiti/Ordinal-Classification-Simulation-Study.git**

$$~$$



```{r, appendix histograms for ordinal distributions, fig.asp=0.6, eval=FALSE, echo=FALSE}
suppressWarnings(suppressPackageStartupMessages(library(tidyverse)))

abc <- tribble(
   ~ Ord_Val, ~ Prop, ~ grp,
   "1",    2.5,    "Normal",
   "2",    13.5,   "Normal",
   "3",    68,     "Normal",
   "4",    13.5,   "Normal",
   "5",    2.5,    "Normal",
   "1",    10,     "Triangular",
   "2",    20,     "Triangular",
   "3",    40,     "Triangular",
   "4",    20,     "Triangular",
   "5",    10,     "Triangular",
   "1",    17,     "Near Uniform",
   "2",    20,     "Near Uniform",
   "3",    26,     "Near Uniform",
   "4",    20,     "Near Uniform",
   "5",    17,     "Near Uniform",
   "1",    30,     "Right Skewed",
   "2",    25,     "Right Skewed",
   "3",    20,     "Right Skewed",
   "4",    15,     "Right Skewed",
   "5",    10,     "Right Skewed",
   "1",    10,     "Left Skewed",
   "2",    15,     "Left Skewed",
   "3",    20,     "Left Skewed",
   "4",    25,     "Left Skewed",
   "5",    30,     "Left Skewed",
   "1",    25,     "Bi-modal",
   "2",    20,     "Bi-modal",
   "3",    10,     "Bi-modal",
   "4",    20,     "Bi-modal",
   "5",    25,     "Bi-modal",
)

abc$grp <- factor(abc$grp, levels = c("Normal", "Triangular", "Near Uniform", "Right Skewed", 
                                      "Left Skewed", "Bi-modal"))

ggplot(abc, aes(x = Ord_Val, y = Prop)) +
   geom_col(color = "black", fill = "dark blue") +
   scale_y_continuous(name = "Proportion ", breaks = seq(0, 100, 10),
                      labels = seq(0, 100, 10), limits = c(0,100)) +
   geom_text(aes(label = Prop, vjust = -0.8)) +
   facet_wrap(~grp) +
   xlab("Ordinal Levels") +
   ggtitle("Distributions for Independent Variables")

```

```{r, appendix scenario table, eval=FALSE, echo=FALSE}

scenarios <- tribble(
   ~Scenario, ~Positive_Falsification, ~Negative_Falsification,
   1, 25, 0,
   2, 50, 0,
   3, 75, 0,
   4, 100, 0,
   5, 0, 25,
   6, 25, 25,
   7, 50, 25,
   8, 75, 25,
   9, 0, 50,
   10, 25, 50,
   11, 50, 50,
   12, 0, 75,
   13, 25, 75,
   14, 0, 100)

table_2 <- xtable::xtable(scenarios, caption = "Perturbation Scenarios for Replacement: Percentages of the original data being replaced. For each scenario, the uninformative, slight, and extreme conditional replacement models were used and the misclassification distributions for each perturbed dataset was simulated for comparison to the original \"historical\" misclassification distribution.  It is important to note that when all independent variables in a model are *(i.i.d.)*, several of the scenarios will be equivalent.", digits = c(rep(0,4)), align = rep("c",4))

xtable::print.xtable(table_2, include.rownames = FALSE)


```

```{r, appendix historical misclassification distribution 1, eval=FALSE, echo=TRUE}


nobs <- 1000




set.seed(1234)  # The seed makes the following exactly reproducible


miss_vec <- c()
for(b in 1:1000){
   
n <- 5

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_1 <- data.frame(Historical_1_Historical = miss_vec)

```

```{r, appendix simulation function 1, eval=FALSE, echo=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
#  

sim_func_1 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 5                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-3 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5)                                         ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_pert, family = "binomial")           ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 1, eval=FALSE, echo=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_1 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_1[[paste0("Uninformative_1_Scenario_",ind)]] <- sim_func_1(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_1 <- as.data.frame(uninformative_1)

```

```{r, appendix slight 1, eval=FALSE, echo=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_1 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_1[[paste0("Slight_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_1 <- as.data.frame(slight_1)

```

```{r, appendix extreme 1, eval=FALSE, echo=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_1 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_1[[paste0("Extreme_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_1 <- as.data.frame(extreme_1)

```

```{r, appendix summary 1, eval=FALSE, echo=TRUE}

df_1 <- tibble(historical_1, uninformative_1, slight_1, extreme_1) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_1_")

df_1$Scenario <- factor(df_1$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_1$Model <- factor(df_1$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


plot_1 <- ggplot(df_1, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('5 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                   theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_1_reduced <- df_1 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_1_reduced <- ggplot(df_1_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('5 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                   theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_1




```

```{r, appendix hypothesis tests of equivalence 1, eval=FALSE, echo=TRUE}

# large sample test of significance comparing distributions of y=xb
# perturbation scenarios 

## Looking for equivalence of distributions

p_func <- function(first_scenario_vector, second_scenario_vector){
 ts <- ks.test(first_scenario_vector, second_scenario_vector, alternative = "two.sided",
               simulate.p.value=TRUE)

 D <- round(ts$statistic[[1]], digits = 3)
 p <- round(ts$p.value[[1]], digits = 3)
paste0(D," (",p,")")
}


# equivalence of sample means

p_func <- function(first_scenario_vector, second_scenario_vector, Nsims = 1000){
 z <- (mean(first_scenario_vector) - mean(second_scenario_vector))/
       sqrt(var(first_scenario_vector)/Nsims + var(second_scenario_vector)/Nsims)

 p <- ifelse(z > 0, 2*pnorm(z, lower.tail = FALSE), 2*pnorm(z))
 z <- round(z, digits = 3)
 p <- round(p, digits = 3)
paste0(z," (",p,")")
}





data_data <- df_1



################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                      filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests1 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests1, names_from = Perturbation, values_from = value)

#################################################################################################

tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations: Kolmogorov-Smirnov 
hypothesis test of difference of distributions for equivalent perturbation scenarios - Five independent, normally distributed ordinal variables - Test statistic (P-value).")

tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations: Large sample hypothesis tests of  equivalent sample mean for equivalent perturbation scenarios - Five independent, normally distributed ordinal variables - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "h")

```



```{r, appendix historical misclassification distribution 1b, eval=FALSE, echo=FALSE}


nobs <- 1000




set.seed(1234)  # The seed makes the following exactly reproducible


miss_vec <- c()
for(b in 1:100){
   
n <- 5

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_1b <- data.frame(Historical_1_Historical = miss_vec)

```

```{r, appendix simulation function 1b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_1 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 5                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-3 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5)                                         ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_pert, family = "binomial")           ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 1b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_1b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_1b[[paste0("Uninformative_1_Scenario_",ind)]] <- sim_func_1(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_1b <- as.data.frame(uninformative_1b)

```

```{r, appendix slight 1b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_1b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_1b[[paste0("Slight_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_1b <- as.data.frame(slight_1b)

```

```{r, appendix extreme 1b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_1b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_1b[[paste0("Extreme_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_1b <- as.data.frame(extreme_1b)

```

```{r, appendix summary 1b, eval=FALSE, echo=FALSE}

df_1b <- tibble(historical_1b, uninformative_1b, slight_1b, extreme_1b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_1_")

df_1b$Scenario <- factor(df_1b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_1b$Model <- factor(df_1b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 1b, eval=FALSE, echo=FALSE}

# large sample test of significance comparing distributions of y=xb
# perturbation scenarios 


data_data <- df_1b



################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                      filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value, 
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value, 
                            Nsims = 100)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value, 
                      Nsims = 100)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value, 
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value, 
                            Nsims = 100)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value, 
                      Nsims = 100)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value, 
                       Nsims = 100)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value, 
                       Nsims = 100)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value, 
                       Nsims = 100)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value, 
                       Nsims = 100)

##################################################################################################

tests1b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests1b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 1c, eval=FALSE, echo=FALSE}


nobs <- 200




set.seed(1234)  # The seed makes the following exactly reproducible


miss_vec <- c()
for(b in 1:1000){
   
n <- 5

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_1c <- data.frame(Historical_1_Historical = miss_vec)

```

```{r, appendix simulation function 1c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_1 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 5                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-3 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5)                                         ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_pert, family = "binomial")           ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 1c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_1c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_1c[[paste0("Uninformative_1_Scenario_",ind)]] <- sim_func_1(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_1c <- as.data.frame(uninformative_1c)

```

```{r, appendix slight 1c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_1c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_1c[[paste0("Slight_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_1c <- as.data.frame(slight_1c)

```

```{r, appendix extreme 1c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_1c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_1c[[paste0("Extreme_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_1c <- as.data.frame(extreme_1c)

```

```{r, appendix summary 1c, eval=FALSE, echo=FALSE}

df_1c <- tibble(historical_1c, uninformative_1c, slight_1c, extreme_1c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_1_")

df_1c$Scenario <- factor(df_1c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_1c$Model <- factor(df_1c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


```

```{r, appendix hypothesis tests of equivalence 1c, eval=FALSE, echo=FALSE}

# large sample test of significance comparing distributions of y=xb
# perturbation scenarios 


data_data <- df_1c



################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                      filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests1c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests1c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 1d, eval=FALSE, echo=FALSE}


nobs <- 200




set.seed(1234)  # The seed makes the following exactly reproducible


miss_vec <- c()
for(b in 1:100){
   
n <- 5

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_1d <- data.frame(Historical_1_Historical = miss_vec)

```

```{r, appendix simulation function 1d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_1 <- function(scenario, model_type, n_sims = 100, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 5                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-3 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5)                                         ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5, data = data_pert, family = "binomial")           ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 1d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_1d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_1d[[paste0("Uninformative_1_Scenario_",ind)]] <- sim_func_1(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_1d <- as.data.frame(uninformative_1d)

```

```{r, appendix slight 1d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_1d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_1d[[paste0("Slight_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_1d <- as.data.frame(slight_1d)

```

```{r, appendix extreme 1d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_1d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_1d[[paste0("Extreme_1_Scenario_",ind)]] <- sim_func_1(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_1d <- as.data.frame(extreme_1d)

```

```{r, appendix summary 1d, eval=FALSE, echo=FALSE}

df_1d <- tibble(historical_1d, uninformative_1d, slight_1d, extreme_1d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_1_")

df_1d$Scenario <- factor(df_1d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_1d$Model <- factor(df_1d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 1d, eval=FALSE, echo=FALSE}

# large sample test of significance comparing distributions of y=xb
# perturbation scenarios 



data_data <- df_1d



################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                      filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value, 
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value, 
                            Nsims = 100)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value, 
                      Nsims = 100)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value, 
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value, 
                            Nsims = 100)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value, 
                      Nsims = 100)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value, 
                       Nsims = 100)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value, 
                       Nsims = 100)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value, 
                       Nsims = 100)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value, 
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value, 
                             Nsims = 100)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value, 
                       Nsims = 100)

##################################################################################################

tests1d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests1d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```


```{r, historical misclassification distribution 1e, echo=FALSE, eval=FALSE, echo=FALSE}


nobs <- 1000




set.seed(1234)  # The seed makes the following exactly reproducible


miss_vec <- c()
for(b in 1:1000){
   
n <- 5

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-0.2 + 0.05*data_long$x1 - 0.048*data_long$x2 + 0.046*data_long$x3 - 
0.044*data_long$x4 + 0.042*data_long$x5)

# summary(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5 -1, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_1e <- data.frame(Historical_1_Historical = miss_vec)

```

```{r, simulation function 1e, echo=FALSE, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
#  

sim_func_1e <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 5                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-0.2 + 0.05*data_long$x1 - 0.048*data_long$x2 + 0.046*data_long$x3 - 
0.044*data_long$x4 + 0.042*data_long$x5)                                     #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-0.2 + 0.05*data_pert$x1 - 0.048*data_pert$x2 + 0.46*data_pert$x3 - 
   0.044*data_pert$x4 + 0.042*data_pert$x5)                                         ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5 -1, data = data_pert, family = "binomial")           ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 1e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_1e <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_1e[[paste0("Uninformative_1_Scenario_",ind)]] <- sim_func_1e(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_1e <- as.data.frame(uninformative_1e)

```

```{r, slight 1e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_1e <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_1e[[paste0("Slight_1_Scenario_",ind)]] <- sim_func_1e(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_1e <- as.data.frame(slight_1e)

```

```{r, extreme 1e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_1e <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_1e[[paste0("Extreme_1_Scenario_",ind)]] <- sim_func_1e(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_1e <- as.data.frame(extreme_1e)

```

```{r, summary 1e, echo=FALSE, eval=FALSE, echo=FALSE}

df_1e <- tibble(historical_1e, uninformative_1e, slight_1e, extreme_1e) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_1_")

df_1e$Scenario <- factor(df_1e$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_1e$Model <- factor(df_1e$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


plot_1e <- ggplot(df_1e, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('5 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                   theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_1e_reduced <- df_1e %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_1e_reduced <- ggplot(df_1e_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('5 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                   theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_1e




```




```{r, appendix historical misclassification distribution 2, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 1000




miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_2 <- data.frame(Historical_2_Historical = miss_vec)

```

```{r, appendix simulation function 2, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_2 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 2, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_2 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_2[[paste0("Uninformative_2_Scenario_",ind)]] <- sim_func_2(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_2 <- as.data.frame(uninformative_2)

```

```{r, appendix slight 2, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_2 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_2[[paste0("Slight_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_2 <- as.data.frame(slight_2)

```

```{r, appendix extreme 2, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_2 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_2[[paste0("Extreme_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_2 <- as.data.frame(extreme_2)

```

```{r, appendix summary 2, eval=FALSE, echo=FALSE}

df_2 <- tibble(historical_2, uninformative_2, slight_2, extreme_2) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_2_")
   

df_2$Scenario <- factor(df_2$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_2$Model <- factor(df_2$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_2 <- ggplot(df_2, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +
               theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_2_reduced <- df_2 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")


plot_2_reduced <- ggplot(df_2_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +
               theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_2


```

```{r, appendix hypothesis tests of equivalence 2, eval=FALSE, echo=FALSE}

data_data <- df_2

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests2 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests2, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 2b, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 1000



miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_2b <- data.frame(Historical_2_Historical = miss_vec)

```

```{r, appendix simulation function 2b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_2 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 2b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_2b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_2b[[paste0("Uninformative_2_Scenario_",ind)]] <- sim_func_2(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_2b <- as.data.frame(uninformative_2b)

```

```{r, appendix slight 2b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_2b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_2b[[paste0("Slight_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_2b <- as.data.frame(slight_2b)

```

```{r, appendix extreme 2b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_2b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_2b[[paste0("Extreme_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_2b <- as.data.frame(extreme_2b)

```

```{r, appendix summary 2b, eval=FALSE, echo=FALSE}

df_2b <- tibble(historical_2b, uninformative_2b, slight_2b, extreme_2b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_2_")
   

df_2b$Scenario <- factor(df_2b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_2b$Model <- factor(df_2b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


```

```{r, appendix hypothesis tests of equivalence 2b, eval=FALSE, echo=FALSE}

data_data <- df_2b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests2b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests2b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 2c, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200



miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_2c <- data.frame(Historical_2_Historical = miss_vec)

```

```{r, appendix simulation function 2c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_2 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 2c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_2c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_2c[[paste0("Uninformative_2_Scenario_",ind)]] <- sim_func_2(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_2c <- as.data.frame(uninformative_2c)

```

```{r, appendix slight 2c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_2c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_2c[[paste0("Slight_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_2c <- as.data.frame(slight_2c)

```

```{r, appendix extreme 2c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_2c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_2c[[paste0("Extreme_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_2c <- as.data.frame(extreme_2c)

```

```{r, appendix summary 2c, eval=FALSE, echo=FALSE}

df_2c <- tibble(historical_2c, uninformative_2c, slight_2c, extreme_2c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_2_")
   

df_2c$Scenario <- factor(df_2c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_2c$Model <- factor(df_2c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


```

```{r, appendix hypothesis tests of equivalence 2c, eval=FALSE, echo=FALSE}

data_data <- df_2c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests2c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests2c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 2d, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200



miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_2d <- data.frame(Historical_2_Historical = miss_vec)

```

```{r, appendix simulation function 2d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_2 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 2d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_2d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_2d[[paste0("Uninformative_2_Scenario_",ind)]] <- sim_func_2(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_2d <- as.data.frame(uninformative_2d)

```

```{r, appendix slight 2d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_2d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_2d[[paste0("Slight_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_2d <- as.data.frame(slight_2d)

```

```{r, appendix extreme 2d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_2d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_2d[[paste0("Extreme_2_Scenario_",ind)]] <- sim_func_2(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_2d <- as.data.frame(extreme_2d)

```

```{r, appendix summary 2d, eval=FALSE, echo=FALSE}

df_2d <- tibble(historical_2d, uninformative_2d, slight_2d, extreme_2d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_2_")
   

df_2d$Scenario <- factor(df_2d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_2d$Model <- factor(df_2d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


```

```{r, appendix hypothesis tests of equivalence 2d, eval=FALSE, echo=FALSE}

data_data <- df_2d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests2d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests2d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - nobs = 200, nsims = 100: Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```


```{r, historical misclassification distribution 2e, echo=FALSE, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 1000




miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.05*data_long$x1 - 0.048*data_long$x2 + 0.046*data_long$x3 - 
0.044*data_long$x4 + 0.042*data_long$x5 - 0.04*data_long$x6 + 0.038*data_long$x7 - 
0.036*data_long$x8 + 0.034*data_long$x9 - 0.032*data_long$x10)
# summary(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_2e <- data.frame(Historical_2_Historical = miss_vec)

```

```{r, simulation function 2e, echo=FALSE, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_2e <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.05*data_long$x1 - 0.048*data_long$x2 + 0.046*data_long$x3 - 
0.044*data_long$x4 + 0.042*data_long$x5 - 0.04*data_long$x6 + 0.038*data_long$x7 - 
0.036*data_long$x8 + 0.034*data_long$x9 - 0.032*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.05*data_pert$x1 - 0.048*data_pert$x2 + 0.046*data_pert$x3 - 
0.044*data_pert$x4 + 0.042*data_pert$x5 - 0.04*data_pert$x6 + 0.038*data_pert$x7 - 
0.036*data_pert$x8 + 0.034*data_pert$x9 - 0.032*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 2e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_2e <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_2e[[paste0("Uninformative_2_Scenario_",ind)]] <- sim_func_2e(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_2e <- as.data.frame(uninformative_2e)

```

```{r, slight 2e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_2e <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_2e[[paste0("Slight_2_Scenario_",ind)]] <- sim_func_2e(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_2e <- as.data.frame(slight_2e)

```

```{r, extreme 2e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_2e <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_2e[[paste0("Extreme_2_Scenario_",ind)]] <- sim_func_2e(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_2e <- as.data.frame(extreme_2e)

```

```{r, summary 2e, echo=FALSE, eval=FALSE, echo=FALSE}

df_2e <- tibble(historical_2e, uninformative_2e, slight_2e, extreme_2e) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_2_")
   

df_2e$Scenario <- factor(df_2e$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_2e$Model <- factor(df_2e$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_2e <- ggplot(df_2e, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +
               theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_2e


```




```{r, appendix historical misclassification distribution 3, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
   
n <- 20

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_3 <- data.frame(Historical_3_Historical = miss_vec)

```

```{r, appendix simulation function 3, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_3 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 20                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)                                                            ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_pert, family = "binomial")                                ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 3, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_3 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_3[[paste0("Uninformative_3_Scenario_",ind)]] <- sim_func_3(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_3 <- as.data.frame(uninformative_3)

```

```{r, appendix slight 3, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_3 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_3[[paste0("Slight_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_3 <- as.data.frame(slight_3)

```

```{r, appendix extreme 3, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_3 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_3[[paste0("Extreme_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_3 <- as.data.frame(extreme_3)

```

```{r, appendix summary 3, eval=FALSE, echo=FALSE}

df_3 <- tibble(historical_3, uninformative_3, slight_3, extreme_3) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_3_")

df_3$Scenario <- factor(df_3$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_3$Model <- factor(df_3$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_3 <- ggplot(df_3, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('20 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_3_reduced <- df_3 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")


plot_3_reduced <- ggplot(df_3_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('20 Independent Variables, Normally Distributed, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_3

```

```{r, appendix hypothesis tests of equivalence 3, eval=FALSE, echo=FALSE}

data_data <- df_3

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests3 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests3, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - nobs = 1000, nsims = 1000: Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 3b, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){
   
n <- 20

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_3b <- data.frame(Historical_3_Historical = miss_vec)

```

```{r, appendix simulation function 3b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_3 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 20                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)                                                            ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_pert, family = "binomial")                                ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 3b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_3b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_3b[[paste0("Uninformative_3_Scenario_",ind)]] <- sim_func_3(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_3b <- as.data.frame(uninformative_3b)

```

```{r, appendix slight 3b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_3b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_3b[[paste0("Slight_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_3b <- as.data.frame(slight_3b)

```

```{r, appendix extreme 3b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_3b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_3b[[paste0("Extreme_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_3b <- as.data.frame(extreme_3b)

```

```{r, appendix summary 3b, eval=FALSE, echo=FALSE}

df_3b <- tibble(historical_3b, uninformative_3b, slight_3b, extreme_3b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_3_")

df_3b$Scenario <- factor(df_3b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_3b$Model <- factor(df_3b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


```

```{r, appendix hypothesis tests of equivalence 3b, eval=FALSE, echo=FALSE}

data_data <- df_3b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value,
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value,
                            Nsims = 100)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value,
                      Nsims = 100)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value,
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value,
                            Nsims = 100)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value,
                      Nsims = 100)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value,
                       Nsims = 100)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value,
                       Nsims = 100)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value,
                       Nsims = 100)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value,
                       Nsims = 100)

##################################################################################################

tests3b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests3b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 3c, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:1000){
   
n <- 20

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_3c <- data.frame(Historical_3_Historical = miss_vec)

```

```{r, appendix simulation function 3c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_3 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 20                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)                                                            ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_pert, family = "binomial")                                ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 3c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_3c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_3c[[paste0("Uninformative_3_Scenario_",ind)]] <- sim_func_3(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_3c <- as.data.frame(uninformative_3c)

```

```{r, appendix slight 3c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_3c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_3c[[paste0("Slight_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_3c <- as.data.frame(slight_3c)

```

```{r, appendix extreme 3c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_3c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_3c[[paste0("Extreme_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_3c <- as.data.frame(extreme_3c)

```

```{r, appendix summary 3c, eval=FALSE, echo=FALSE}

df_3c <- tibble(historical_3c, uninformative_3c, slight_3c, extreme_3c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_3_")

df_3c$Scenario <- factor(df_3c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_3c$Model <- factor(df_3c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 3c, eval=FALSE, echo=FALSE}

data_data <- df_3c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests3c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests3c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 3d, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:100){
   
n <- 20

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_3d <- data.frame(Historical_3_Historical = miss_vec)

```

```{r, appendix simulation function 3d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_3 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 20                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-3 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
   0.75*data_long$x4 + 0.7*data_long$x5)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-2 + 1.2*data_long$x1 - 1.15*data_long$x2 + 1.1*data_long$x3 - 
1.05*data_long$x4 + 1*data_long$x5 - 0.95*data_long$x6 + 0.9*data_long$x7 - 
0.85*data_long$x8 + 0.8*data_long$x9 - 0.75*data_long$x10 + 0.7*data_long$x11 - 
0.65*data_long$x12 + 0.6*data_long$x13 - 0.55*data_long$x14 + 0.5*data_long$x15 - 
0.45*data_long$x16 + 0.4*data_long$x17 - 0.35*data_long$x18 + 0.3*data_long$x19 - 
0.25*data_long$x20)                                                            ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_pert, family = "binomial")                                ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 3d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_3d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_3d[[paste0("Uninformative_3_Scenario_",ind)]] <- sim_func_3(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_3d <- as.data.frame(uninformative_3d)

```

```{r, appendix slight 3d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_3d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_3d[[paste0("Slight_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_3d <- as.data.frame(slight_3d)

```

```{r, appendix extreme 3d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_3d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_3d[[paste0("Extreme_3_Scenario_",ind)]] <- sim_func_3(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_3d <- as.data.frame(extreme_3d)

```

```{r, appendix summary 3d, eval=FALSE, echo=FALSE}

df_3d <- tibble(historical_3d, uninformative_3d, slight_3d, extreme_3d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_3_")

df_3d$Scenario <- factor(df_3d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_3d$Model <- factor(df_3d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))


```

```{r, appendix hypothesis tests of equivalence 3d, eval=FALSE, echo=FALSE}

data_data <- df_3d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value,
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value,
                            Nsims = 100)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value,
                      Nsims = 100)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value,
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value,
                            Nsims = 100)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value,
                      Nsims = 100)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value,
                       Nsims = 100)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value,
                       Nsims = 100)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value,
                       Nsims = 100)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value,
                       Nsims = 100)

##################################################################################################

tests3d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests3d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```


```{r, historical misclassification distribution 3e, echo=FALSE, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
   
n <- 20

size <- nobs
probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)
x <- rmultinom(n=n, size=size, prob=probs_1)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.056*data_long$x1 - 0.054*data_long$x2 + 0.052*data_long$x3 - 
0.05*data_long$x4 + 0.048*data_long$x5 - 0.046*data_long$x6 + 0.044*data_long$x7 - 
0.042*data_long$x8 + 0.04*data_long$x9 - 0.038*data_long$x10 + 0.036*data_long$x11 - 
0.034*data_long$x12 + 0.032*data_long$x13 - 0.03*data_long$x14 + 0.028*data_long$x15 - 
0.026*data_long$x16 + 0.024*data_long$x17 - 0.022*data_long$x18 + 0.02*data_long$x19 - 
0.018*data_long$x20) 

#summary(data_long$xb)


data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_3e <- data.frame(Historical_3_Historical = miss_vec)

```

```{r, simulation function 3e, echo=FALSE, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_3e <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){  ######

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
n <- 20                                                                       #######

size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.056*data_long$x1 - 0.054*data_long$x2 + 0.052*data_long$x3 - 
0.05*data_long$x4 + 0.048*data_long$x5 - 0.046*data_long$x6 + 0.044*data_long$x7 - 
0.042*data_long$x8 + 0.04*data_long$x9 - 0.038*data_long$x10 + 0.036*data_long$x11 - 
0.034*data_long$x12 + 0.032*data_long$x13 - 0.03*data_long$x14 + 0.028*data_long$x15 - 
0.026*data_long$x16 + 0.024*data_long$x17 - 0.022*data_long$x18 + 0.02*data_long$x19 - 
0.018*data_long$x20)                                       #######

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.056*data_pert$x1 - 0.054*data_pert$x2 + 0.052*data_pert$x3 - 
0.05*data_pert$x4 + 0.048*data_pert$x5 - 0.046*data_pert$x6 + 0.044*data_pert$x7 - 
0.042*data_pert$x8 + 0.04*data_pert$x9 - 0.038*data_pert$x10 + 0.036*data_pert$x11 - 
0.034*data_pert$x12 + 0.032*data_pert$x13 - 0.03*data_pert$x14 + 0.028*data_pert$x15 - 
0.026*data_pert$x16 + 0.024*data_pert$x17 - 0.022*data_pert$x18 + 0.02*data_pert$x19 - 
0.018*data_pert$x20)                                                           ########

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20, 
           data = data_pert, family = "binomial")                                ########
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, uninformative 3e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
uninformative_3e <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_3e[[paste0("Uninformative_3_Scenario_",ind)]] <- sim_func_3e(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_3e <- as.data.frame(uninformative_3e)

```

```{r, slight 3e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
slight_3e <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_3e[[paste0("Slight_3_Scenario_",ind)]] <- sim_func_3e(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_3e <- as.data.frame(slight_3e)

```

```{r, extreme 3e, echo=FALSE, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)

# initialize list for output
extreme_3e <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_3e[[paste0("Extreme_3_Scenario_",ind)]] <- sim_func_3e(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_1, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_3e <- as.data.frame(extreme_3e)

```

```{r, summary 3e, echo=FALSE, eval=FALSE, echo=FALSE}

df_3e <- tibble(historical_3e, uninformative_3e, slight_3e, extreme_3e) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_3_")

df_3e$Scenario <- factor(df_3e$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_3e$Model <- factor(df_3e$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_3e <- ggplot(df_3e, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('20 Independent Variables, Normally Distributed') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_3e

```




```{r, appendix historical misclassification distribution 4, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_2)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_4 <- data.frame(Historical_4_Historical = miss_vec)

```

```{r, appendix simulation function 4, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_4 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 4, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
uninformative_4 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_4[[paste0("Uninformative_4_Scenario_",ind)]] <- sim_func_4(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_4 <- as.data.frame(uninformative_4)

```

```{r, appendix slight 4, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
slight_4 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_4[[paste0("Slight_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_4 <- as.data.frame(slight_4)

```

```{r, appendix extreme 4, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
extreme_4 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_4[[paste0("Extreme_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_4 <- as.data.frame(extreme_4)

```

```{r, appendix summary 4, eval=FALSE, echo=FALSE}

df_4 <- tibble(historical_4, uninformative_4, slight_4, extreme_4) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_4_")

df_4$Scenario <- factor(df_4$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_4$Model <- factor(df_4$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_4 <- ggplot(df_4, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Triangular Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_4_reduced <- df_4 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")


plot_4_reduced <- ggplot(df_4_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Triangular Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


plot_4


```

```{r, appendix hypothesis tests of equivalence 4, eval=FALSE, echo=FALSE}

data_data <- df_4

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests4 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests4, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 4b, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_2)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_4b <- data.frame(Historical_4_Historical = miss_vec)

```

```{r, appendix simulation function 4b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_4 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 4b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
uninformative_4b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_4b[[paste0("Uninformative_4_Scenario_",ind)]] <- sim_func_4(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_4b <- as.data.frame(uninformative_4b)

```

```{r, appendix slight 4b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
slight_4b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_4b[[paste0("Slight_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_4b <- as.data.frame(slight_4b)

```

```{r, appendix extreme 4b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
extreme_4b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_4b[[paste0("Extreme_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_4b <- as.data.frame(extreme_4b)

```

```{r, appendix summary 4b, eval=FALSE, echo=FALSE}

df_4b <- tibble(historical_4b, uninformative_4b, slight_4b, extreme_4b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_4_")

df_4b$Scenario <- factor(df_4b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_4b$Model <- factor(df_4b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 4b, eval=FALSE, echo=FALSE}

data_data <- df_4b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests4b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests4b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 4c, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_2)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_4c <- data.frame(Historical_4_Historical = miss_vec)

```

```{r, appendix simulation function 4c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_4 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 4c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
uninformative_4c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_4c[[paste0("Uninformative_4_Scenario_",ind)]] <- sim_func_4(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_4c <- as.data.frame(uninformative_4c)

```

```{r, appendix slight 4c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
slight_4c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_4c[[paste0("Slight_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_4c <- as.data.frame(slight_4c)

```

```{r, appendix extreme 4c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
extreme_4c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_4c[[paste0("Extreme_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_4c <- as.data.frame(extreme_4c)

```

```{r, appendix summary 4c, eval=FALSE, echo=FALSE}

df_4c <- tibble(historical_4c, uninformative_4c, slight_4c, extreme_4c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_4_")

df_4c$Scenario <- factor(df_4c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_4c$Model <- factor(df_4c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 4c, eval=FALSE, echo=FALSE}

data_data <- df_4c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests4c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests4c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 4d, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_2)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)
data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial")
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_4d <- data.frame(Historical_4_Historical = miss_vec)

```

```{r, appendix simulation function 4d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_4 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.25 + 0.9*data_long$x1 - 0.85*data_long$x2 + 0.8*data_long$x3 - 
0.75*data_long$x4 + 0.7*data_long$x5 - 0.65*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.5*data_long$x9 - 0.45*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.25 + 0.9*data_pert$x1 - 0.85*data_pert$x2 + 0.8*data_pert$x3 - 
   0.75*data_pert$x4 + 0.7*data_pert$x5 - 0.65*data_pert$x6 + 0.6*data_pert$x7 - 0.55*data_pert$x8 + 0.5*data_pert$x9 - 0.45*data_pert$x10)

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 4d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
uninformative_4d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_4d[[paste0("Uninformative_4_Scenario_",ind)]] <- sim_func_4(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_4d <- as.data.frame(uninformative_4d)

```

```{r, appendix slight 4d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
slight_4d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_4d[[paste0("Slight_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_4d <- as.data.frame(slight_4d)

```

```{r, appendix extreme 4d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)

# initialize list for output
extreme_4d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_4d[[paste0("Extreme_4_Scenario_",ind)]] <- sim_func_4(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_2, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_4d <- as.data.frame(extreme_4d)

```

```{r, appendix summary 4d, eval=FALSE, echo=FALSE}

df_4d <- tibble(historical_4d, uninformative_4d, slight_4d, extreme_4d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_4_")

df_4d$Scenario <- factor(df_4d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_4d$Model <- factor(df_4d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 4d, eval=FALSE, echo=FALSE}

data_data <- df_4d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests4d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests4d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 5, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 1000



miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

x <- rmultinom(n=n, size=size, prob=probs_3)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_5 <- data.frame(Historical_5_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 5, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_5 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 5, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
uninformative_5 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_5[[paste0("Uninformative_5_Scenario_",ind)]] <- sim_func_5(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_5 <- as.data.frame(uninformative_5)

```

```{r, appendix slight 5, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
slight_5 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_5[[paste0("Slight_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_5 <- as.data.frame(slight_5)

```

```{r, appendix extreme 5, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
extreme_5 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_5[[paste0("Extreme_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_5 <- as.data.frame(extreme_5)

```

```{r, appendix summary 5, eval=FALSE, echo=FALSE}

df_5 <- tibble(historical_5, uninformative_5, slight_5, extreme_5) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_5_")

df_5$Scenario <- factor(df_5$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_5$Model <- factor(df_5$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_5 <- ggplot(df_5, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Near Uniform Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_5_reduced <- df_5 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_5_reduced <- ggplot(df_5_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Near Uniform Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_5


```

```{r, appendix hypothesis tests of equivalence 5, eval=FALSE, echo=FALSE}


data_data <- df_5

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests5 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests5, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 5b, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

x <- rmultinom(n=n, size=size, prob=probs_3)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_5b <- data.frame(Historical_5_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 5b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_5 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 5b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
uninformative_5b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_5b[[paste0("Uninformative_5_Scenario_",ind)]] <- sim_func_5(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_5b <- as.data.frame(uninformative_5b)

```

```{r, appendix slight 5b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
slight_5b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_5b[[paste0("Slight_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_5b <- as.data.frame(slight_5b)

```

```{r, appendix extreme 5b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
extreme_5b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_5b[[paste0("Extreme_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_5b <- as.data.frame(extreme_5b)

```

```{r, appendix summary 5b, eval=FALSE, echo=FALSE}

df_5b <- tibble(historical_5b, uninformative_5b, slight_5b, extreme_5b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_5_")

df_5b$Scenario <- factor(df_5b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_5b$Model <- factor(df_5b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 5b, eval=FALSE, echo=FALSE}


data_data <- df_5b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests5b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests5b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 5c, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200



miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

x <- rmultinom(n=n, size=size, prob=probs_3)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_5c <- data.frame(Historical_5_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 5c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_5 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 5c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
uninformative_5c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_5c[[paste0("Uninformative_5_Scenario_",ind)]] <- sim_func_5(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_5c <- as.data.frame(uninformative_5c)

```

```{r, appendix slight 5c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
slight_5c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_5c[[paste0("Slight_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_5c <- as.data.frame(slight_5c)

```

```{r, appendix extreme 5c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
extreme_5c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_5c[[paste0("Extreme_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_5c <- as.data.frame(extreme_5c)

```

```{r, appendix summary 5c, eval=FALSE, echo=FALSE}

df_5c <- tibble(historical_5c, uninformative_5c, slight_5c, extreme_5c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_5_")

df_5c$Scenario <- factor(df_5c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_5c$Model <- factor(df_5c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 5c, eval=FALSE, echo=FALSE}


data_data <- df_5c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests5c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests5c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 5d, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible



nobs <- 200


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

x <- rmultinom(n=n, size=size, prob=probs_3)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_5d <- data.frame(Historical_5_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 5d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_5 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10 -1, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 5d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
uninformative_5d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_5d[[paste0("Uninformative_5_Scenario_",ind)]] <- sim_func_5(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_5d <- as.data.frame(uninformative_5d)

```

```{r, appendix slight 5d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
slight_5d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_5d[[paste0("Slight_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_5d <- as.data.frame(slight_5d)

```

```{r, appendix extreme 5d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)

# initialize list for output
extreme_5d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_5d[[paste0("Extreme_5_Scenario_",ind)]] <- sim_func_5(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_3, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_5d <- as.data.frame(extreme_5d)

```

```{r, appendix summary 5d, eval=FALSE, echo=FALSE}

df_5d <- tibble(historical_5d, uninformative_5d, slight_5d, extreme_5d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_5_")

df_5d$Scenario <- factor(df_5d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_5d$Model <- factor(df_5d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 5d, eval=FALSE, echo=FALSE}


data_data <- df_5d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests5d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests5d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 6, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

x <- rmultinom(n=n, size=size, prob=probs_4)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_6 <- data.frame(Historical_6_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 6, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_6 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 6, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
uninformative_6 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_6[[paste0("Uninformative_6_Scenario_",ind)]] <- sim_func_6(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_6 <- as.data.frame(uninformative_6)

```

```{r, appendix slight 6, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
slight_6 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_6[[paste0("Slight_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_6 <- as.data.frame(slight_6)

```

```{r, appendix extreme 6, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
extreme_6 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_6[[paste0("Extreme_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_6 <- as.data.frame(extreme_6)

```

```{r, appendix summary 6, eval=FALSE, echo=FALSE}

df_6 <- tibble(historical_6, uninformative_6, slight_6, extreme_6) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_6_")

df_6$Scenario <- factor(df_6$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_6$Model <- factor(df_6$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_6 <- ggplot(df_6, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Bi-modal Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_6_reduced <- df_6 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_6_reduced <- ggplot(df_6_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Bi-modal Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_6


```

```{r, appendix hypothesis tests of equivalence 6, eval=FALSE, echo=FALSE}

data_data <- df_6

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests6 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests6, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 6b, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

x <- rmultinom(n=n, size=size, prob=probs_4)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_6b <- data.frame(Historical_6_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 6b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_6 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 6b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
uninformative_6b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_6b[[paste0("Uninformative_6_Scenario_",ind)]] <- sim_func_6(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_6b <- as.data.frame(uninformative_6b)

```

```{r, appendix slight 6b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
slight_6b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_6b[[paste0("Slight_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_6b <- as.data.frame(slight_6b)

```

```{r, appendix extreme 6b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
extreme_6b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_6b[[paste0("Extreme_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_6b <- as.data.frame(extreme_6b)

```

```{r, appendix summary 6b, eval=FALSE, echo=FALSE}

df_6b <- tibble(historical_6b, uninformative_6b, slight_6b, extreme_6b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_6_")

df_6b$Scenario <- factor(df_6b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_6b$Model <- factor(df_6b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 6b, eval=FALSE, echo=FALSE}

data_data <- df_6b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests6b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests6b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 6c, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

x <- rmultinom(n=n, size=size, prob=probs_4)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_6c <- data.frame(Historical_6_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 6c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_6 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 6c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
uninformative_6c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_6c[[paste0("Uninformative_6_Scenario_",ind)]] <- sim_func_6(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_6c <- as.data.frame(uninformative_6c)

```

```{r, appendix slight 6c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
slight_6c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_6c[[paste0("Slight_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_6c <- as.data.frame(slight_6c)

```

```{r, appendix extreme 6c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
extreme_6c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_6c[[paste0("Extreme_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_6c <- as.data.frame(extreme_6c)

```

```{r, appendix summary 6c, eval=FALSE, echo=FALSE}

df_6c <- tibble(historical_6c, uninformative_6c, slight_6c, extreme_6c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_6_")

df_6c$Scenario <- factor(df_6c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_6c$Model <- factor(df_6c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 6c, eval=FALSE, echo=FALSE}

data_data <- df_6c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests6c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests6c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 6d, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

x <- rmultinom(n=n, size=size, prob=probs_4)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_6d <- data.frame(Historical_6_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 6d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_6 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 6d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
uninformative_6d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_6d[[paste0("Uninformative_6_Scenario_",ind)]] <- sim_func_6(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_6d <- as.data.frame(uninformative_6d)

```

```{r, appendix slight 6d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
slight_6d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_6d[[paste0("Slight_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_6d <- as.data.frame(slight_6d)

```

```{r, appendix extreme 6d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)

# initialize list for output
extreme_6d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_6d[[paste0("Extreme_6_Scenario_",ind)]] <- sim_func_6(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_4, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_6d <- as.data.frame(extreme_6d)

```

```{r, appendix summary 6d, eval=FALSE, echo=FALSE}

df_6d <- tibble(historical_6d, uninformative_6d, slight_6d, extreme_6d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_6_")

df_6d$Scenario <- factor(df_6d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_6d$Model <- factor(df_6d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 6d, eval=FALSE, echo=FALSE}

data_data <- df_6d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests6d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests6d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 7, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_5)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_7 <- data.frame(Historical_7_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 7, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_7 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 7, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
uninformative_7 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_7[[paste0("Uninformative_7_Scenario_",ind)]] <- sim_func_7(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_7 <- as.data.frame(uninformative_7)

```

```{r, appendix slight 7, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
slight_7 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_7[[paste0("Slight_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_7 <- as.data.frame(slight_7)

```

```{r, appendix extreme 7, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
extreme_7 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_7[[paste0("Extreme_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_7 <- as.data.frame(extreme_7)

```

```{r, appendix summary 7, eval=FALSE, echo=FALSE}

df_7 <- tibble(historical_7, uninformative_7, slight_7, extreme_7) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_7_")

df_7$Scenario <- factor(df_7$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_7$Model <- factor(df_7$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_7 <- ggplot(df_7, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Right-Skewed Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_7_reduced <- df_7 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_7_reduced <- ggplot(df_7_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Right-Skewed Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_7


```

```{r, appendix hypothesis tests of equivalence 7, eval=FALSE, echo=FALSE}

data_data <- df_7

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests7 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests7, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 7b, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_5)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_7b <- data.frame(Historical_7_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 7b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_7 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 7b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
uninformative_7b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_7b[[paste0("Uninformative_7_Scenario_",ind)]] <- sim_func_7(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_7b <- as.data.frame(uninformative_7b)

```

```{r, appendix slight 7b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
slight_7b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_7b[[paste0("Slight_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_7b <- as.data.frame(slight_7b)

```

```{r, appendix extreme 7b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
extreme_7b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_7b[[paste0("Extreme_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_7b <- as.data.frame(extreme_7b)

```

```{r, appendix summary 7b, eval=FALSE, echo=FALSE}

df_7b <- tibble(historical_7b, uninformative_7b, slight_7b, extreme_7b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_7_")

df_7b$Scenario <- factor(df_7b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_7b$Model <- factor(df_7b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 7b, eval=FALSE, echo=FALSE}

data_data <- df_7b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests7b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests7b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 7c, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_5)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_7c <- data.frame(Historical_7_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 7c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_7 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 7c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
uninformative_7c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_7c[[paste0("Uninformative_7_Scenario_",ind)]] <- sim_func_7(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_7c <- as.data.frame(uninformative_7c)

```

```{r, appendix slight 7c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
slight_7c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_7c[[paste0("Slight_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_7c <- as.data.frame(slight_7c)

```

```{r, appendix extreme 7c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
extreme_7c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_7c[[paste0("Extreme_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_7c <- as.data.frame(extreme_7c)

```

```{r, appendix summary 7c, eval=FALSE, echo=FALSE}

df_7c <- tibble(historical_7c, uninformative_7c, slight_7c, extreme_7c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_7_")

df_7c$Scenario <- factor(df_7c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_7c$Model <- factor(df_7c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 7c, eval=FALSE, echo=FALSE}

data_data <- df_7c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests7c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests7c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 7d, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:100){
n <- 10
size <- nobs

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

x <- rmultinom(n=n, size=size, prob=probs_5)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_7d <- data.frame(Historical_7_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 7d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_7 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 7d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
uninformative_7d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_7d[[paste0("Uninformative_7_Scenario_",ind)]] <- sim_func_7(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_7d <- as.data.frame(uninformative_7d)

```

```{r, appendix slight 7d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
slight_7d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_7d[[paste0("Slight_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 100)
   ind <- ind+1
}
slight_7d <- as.data.frame(slight_7d)

```

```{r, appendix extreme 7d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)

# initialize list for output
extreme_7d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_7d[[paste0("Extreme_7_Scenario_",ind)]] <- sim_func_7(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_5, 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_7d <- as.data.frame(extreme_7d)

```

```{r, appendix summary 7d, eval=FALSE, echo=FALSE}

df_7d <- tibble(historical_7d, uninformative_7d, slight_7d, extreme_7d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_7_")

df_7d$Scenario <- factor(df_7d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_7d$Model <- factor(df_7d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 7d, eval=FALSE, echo=FALSE}

data_data <- df_7d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests7d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests7d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 8, eval=FALSE, echo=FALSE}


set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){
n <- 10
size <- nobs

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

x <- rmultinom(n=n, size=size, prob=probs_6)          ##############
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_long$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 - 
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_long, family = "binomial") ###############
data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_8 <- data.frame(Historical_8_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 8, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_8 <- function(scenario, model_type, n_sims = 1000, ord_prob_dist){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
n <- 10
size <- nobs

x <- rmultinom(n=n, size=size, prob=ord_prob_dist)
row.names(x) <- c("1", "2", "3", "4", "5")
colnames(x) <- paste("x", 1:n, sep = "")
data <- as.data.frame(x)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))
colnames(data_long) <- colnames(x)
for(i in names(data)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.8*data_long$x1 - 0.75*data_long$x2 + 0.7*data_long$x3 - 
0.65*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.5*data_long$x7 -    ##################
0.45*data_long$x8 + 0.4*data_long$x9 - 0.35*data_long$x10)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.8*data_pert$x1 - 0.75*data_pert$x2 + 0.7*data_pert$x3 - 
0.65*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.5*data_pert$x7 - 
0.45*data_pert$x8 + 0.4*data_pert$x9 - 0.35*data_pert$x10)                       ##################

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 8, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

# initialize list for output
uninformative_8 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_8[[paste0("Uninformative_8_Scenario_",ind)]] <- sim_func_8(
                                           scenario = scenario, 
                                           model_type = "uninformative", 
                                           ord_prob_dist = probs_6, 
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_8 <- as.data.frame(uninformative_8)

```

```{r, appendix slight 8, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

# initialize list for output
slight_8 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_8[[paste0("Slight_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "slight", 
                                           ord_prob_dist = probs_6, 
                                           n_sims = 1000)
   ind <- ind+1
}
slight_8 <- as.data.frame(slight_8)

```

```{r, appendix extreme 8, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))

probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)

# initialize list for output
extreme_8 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_8[[paste0("Extreme_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "extreme", 
                                           ord_prob_dist = probs_6, 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_8 <- as.data.frame(extreme_8)

```

```{r, appendix summary 8, eval=FALSE, echo=FALSE}

df_8 <- tibble(historical_8, uninformative_8, slight_8, extreme_8) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_8_")

df_8$Scenario <- factor(df_8$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_8$Model <- factor(df_8$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_8 <- ggplot(df_8, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Left-Skewed Distribution') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

df_8_reduced <- df_8 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")

plot_8_reduced <- ggplot(df_8_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('10 Independent Variables, Left-Skewed Distribution, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')

plot_8


```



```{r, appendix historical misclassification distribution 9, eval=FALSE, echo=FALSE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){

size <- nobs
n <- 12


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_9 <- data.frame(Historical_9_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 9, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_9 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 12
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.6*data_pert$x1 - 0.55*data_pert$x2 + 0.6*data_pert$x3 - 
0.55*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.6*data_pert$x7 - 
0.55*data_pert$x8 + 0.6*data_pert$x9 - 0.55*data_pert$x10 + 
0.6*data_pert$x11 - 0.55*data_pert$x12)                       

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 9, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_9 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_9[[paste0("Uninformative_9_Scenario_",ind)]] <- sim_func_9(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_9 <- as.data.frame(uninformative_9)

```

```{r, appendix slight 9, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_9 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_9[[paste0("Slight_9_Scenario_",ind)]] <- sim_func_9(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 1000)
   ind <- ind+1
}
slight_9 <- as.data.frame(slight_9)

```

```{r, appendix extreme 9, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_9 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_9[[paste0("Extreme_9_Scenario_",ind)]] <- sim_func_9(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_9 <- as.data.frame(extreme_9)

```

```{r, appendix summary 9, eval=FALSE, echo=FALSE}

df_9 <- tibble(historical_9, uninformative_9, slight_9, extreme_9) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_9_")

df_9$Scenario <- factor(df_9$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_9$Model <- factor(df_9$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_9 <- ggplot(df_9, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('12 Independent Variables, Mixed Distributions') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_9_reduced <- df_9 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")



plot_9_reduced <- ggplot(df_9_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('12 Independent Variables, Mixed Distributions, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = "Boxplots showing misclassification distributions for 1000 simulations of each unique scenario and replacement \n model (perturbation) type.")


plot_9


```

```{r, appendix hypothesis tests of equivalence 9, eval=FALSE, echo=FALSE}

data_data <- df_9

# Nothing below this point has been updated to _9 from _8


################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests8 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests8, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 8b, eval=FALSE, echo=FALSE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:100){

size <- nobs
n <- 12


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_8b <- data.frame(Historical_8_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 8b, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_8 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 12
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.6*data_pert$x1 - 0.55*data_pert$x2 + 0.6*data_pert$x3 - 
0.55*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.6*data_pert$x7 - 
0.55*data_pert$x8 + 0.6*data_pert$x9 - 0.55*data_pert$x10 + 
0.6*data_pert$x11 - 0.55*data_pert$x12)                       

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 8b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_8b <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_8b[[paste0("Uninformative_8_Scenario_",ind)]] <- sim_func_8(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_8b <- as.data.frame(uninformative_8b)

```

```{r, appendix slight 8b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_8b <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_8b[[paste0("Slight_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 100)
   ind <- ind+1
}
slight_8b <- as.data.frame(slight_8b)

```

```{r, appendix extreme 8b, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_8b <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_8b[[paste0("Extreme_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_8b <- as.data.frame(extreme_8b)

```

```{r, appendix summary 8b, eval=FALSE, echo=FALSE}

df_8b <- tibble(historical_8b, uninformative_8b, slight_8b, extreme_8b) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_8_")

df_8b$Scenario <- factor(df_8b$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_8b$Model <- factor(df_8b$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 8b, eval=FALSE, echo=FALSE}

data_data <- df_8b

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value,
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value,
                            Nsims = 100)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value,
                      Nsims = 100)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value,
                     Nsims = 100)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value,
                            Nsims = 100)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value,
                      Nsims = 100)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value,
                       Nsims = 100)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value,
                       Nsims = 100)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value,
                       Nsims = 100)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value,
                      Nsims = 100)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value,
                             Nsims = 100)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value,
                       Nsims = 100)

##################################################################################################

tests8b <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests8b, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 8c, eval=FALSE, echo=FALSE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:1000){

size <- nobs
n <- 12


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_8c <- data.frame(Historical_8_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 8c, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_8 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 12
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.6*data_pert$x1 - 0.55*data_pert$x2 + 0.6*data_pert$x3 - 
0.55*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.6*data_pert$x7 - 
0.55*data_pert$x8 + 0.6*data_pert$x9 - 0.55*data_pert$x10 + 
0.6*data_pert$x11 - 0.55*data_pert$x12)                       

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 8c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_8c <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_8c[[paste0("Uninformative_8_Scenario_",ind)]] <- sim_func_8(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_8c <- as.data.frame(uninformative_8c)

```

```{r, appendix slight 8c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_8c <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_8c[[paste0("Slight_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 1000)
   ind <- ind+1
}
slight_8c <- as.data.frame(slight_8c)

```

```{r, appendix extreme 8c, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_8c <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_8c[[paste0("Extreme_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_8c <- as.data.frame(extreme_8c)

```

```{r, appendix summary 8c, eval=FALSE, echo=FALSE}

df_8c <- tibble(historical_8c, uninformative_8c, slight_8c, extreme_8c) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_8_")

df_8c$Scenario <- factor(df_8c$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_8c$Model <- factor(df_8c$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 8c, eval=FALSE, echo=FALSE}

data_data <- df_8c

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests8c <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests8c, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 1000 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```



```{r, appendix historical misclassification distribution 8d, eval=FALSE, echo=FALSE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 200


miss_vec <- c()
for(b in 1:100){

size <- nobs
n <- 12


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)           #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_8d <- data.frame(Historical_8_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 8d, eval=FALSE, echo=FALSE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_8 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 12
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=2, size=size, prob=probs_1)
mix_2 <- rmultinom(n=2, size=size, prob=probs_2)
mix_3 <- rmultinom(n=2, size=size, prob=probs_3)
mix_4 <- rmultinom(n=2, size=size, prob=probs_4)
mix_5 <- rmultinom(n=2, size=size, prob=probs_5)
mix_6 <- rmultinom(n=2, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1 + 0.6*data_long$x1 - 0.55*data_long$x2 + 0.6*data_long$x3 - 
0.55*data_long$x4 + 0.6*data_long$x5 - 0.55*data_long$x6 + 0.6*data_long$x7 - 
0.55*data_long$x8 + 0.6*data_long$x9 - 0.55*data_long$x10 + 
0.6*data_long$x11 - 0.55*data_long$x12)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1 + 0.6*data_pert$x1 - 0.55*data_pert$x2 + 0.6*data_pert$x3 - 
0.55*data_pert$x4 + 0.6*data_pert$x5 - 0.55*data_pert$x6 + 0.6*data_pert$x7 - 
0.55*data_pert$x8 + 0.6*data_pert$x9 - 0.55*data_pert$x10 + 
0.6*data_pert$x11 - 0.55*data_pert$x12)                       

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 8d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_8d <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_8d[[paste0("Uninformative_8_Scenario_",ind)]] <- sim_func_8(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 100)
   ind <- ind+1
}
uninformative_8d <- as.data.frame(uninformative_8d)

```

```{r, appendix slight 8d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_8d <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_8d[[paste0("Slight_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 100)
   ind <- ind+1
}
slight_8d <- as.data.frame(slight_8d)

```

```{r, appendix extreme 8d, eval=FALSE, echo=FALSE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_8d <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_8d[[paste0("Extreme_8_Scenario_",ind)]] <- sim_func_8(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 100)
   ind <- ind+1
}
extreme_8d <- as.data.frame(extreme_8d)

```

```{r, appendix summary 8d, eval=FALSE, echo=FALSE}

df_8d <- tibble(historical_8d, uninformative_8d, slight_8d, extreme_8d) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_8_")

df_8d$Scenario <- factor(df_8d$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_8d$Model <- factor(df_8d$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

```

```{r, appendix hypothesis tests of equivalence 8d, eval=FALSE, echo=FALSE}

data_data <- df_8d

################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                     filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                     filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                            filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests8d <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests8d, names_from = Perturbation, values_from = value)
tests_w_table <- xtable::xtable(tests_w, caption = "200 Observations and 100 Simulations:  Large sample hypothesis test of difference of sample means for equivalent perturbation scenarios - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "tbp")

```




```{r, appendix historical misclassification distribution 10, eval=FALSE, echo=FALSE, cache=TRUE}

set.seed(1234)  # The seed makes the following exactly reproducible


nobs <- 1000


miss_vec <- c()
for(b in 1:1000){

size <- nobs
n <- 30


probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed


mix_1 <- rmultinom(n=5, size=size, prob=probs_1)
mix_2 <- rmultinom(n=5, size=size, prob=probs_2)
mix_3 <- rmultinom(n=5, size=size, prob=probs_3)
mix_4 <- rmultinom(n=5, size=size, prob=probs_4)
mix_5 <- rmultinom(n=5, size=size, prob=probs_5)
mix_6 <- rmultinom(n=5, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)
for(i in names(mixed)){
    data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}


data_long$xb <- (-1.5 + 0.66*data_long$x1 - 0.64*data_long$x2 + 0.62*data_long$x3 - 
0.6*data_long$x4 + 0.58*data_long$x5 - 0.56*data_long$x6 + 0.54*data_long$x7 - 
0.52*data_long$x8 + 0.5*data_long$x9 - 0.48*data_long$x10 + 0.46*data_long$x11 - 
0.44*data_long$x12 + 0.42*data_long$x13 - 0.4*data_long$x14 + 0.38*data_long$x15 - 
0.36*data_long$x16 + 0.34*data_long$x17 - 0.32*data_long$x18 + 0.3*data_long$x19 - 
0.28*data_long$x20 + 0.26*data_long$x21 - 0.24*data_long$x22 + 0.22*data_long$x23 - 
0.2*data_long$x24 + 0.18*data_long$x25 - 0.16*data_long$x26 + 0.14*data_long$x27 - 
0.12*data_long$x28 + 0.1*data_long$x29 - 0.08*data_long$x30)          #####################

# summary(data_long$xb)
# hist(data_long$xb)

data_long$p <- exp(data_long$xb)/(1 + exp(data_long$xb))
data_long$y <- rbinom(n=nrow(data_long) , size = 1, prob = data_long$p)

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
              x21+x22+x23+x24+x25+x26+x27+x28+x29+x30, 
           data = data_long, family = "binomial") ###############

data_long$p_hat <- as.vector(predict(fit, type = "response"))
data_long$y_hat <- ifelse(data_long$p_hat < 0.5,0,1)      

a <- ifelse(data_long$y==data_long$y_hat, 0, 1)
miss_vec[b] <- mean(a) # misclassification rate
}

historical_10 <- data.frame(Historical_10_Historical = miss_vec)    ##############

```

```{r, appendix simulation function 10, echo=FALSE, eval=FALSE, cache=TRUE}

# scenario - vector of 2 elements {e.g., c(0.25,0.25)}
# model_type - one of "uninformative", "slight", "extreme", "average"
# n_sims - number of simulations; default = 1000
# ord_prob_dist - vector of probabilities for ordinal independent variable distribution 
#  {e.g., c(0.1, 0.2, 0.3, 0.3, 0.1)} - must sum to 1
   
sim_func_10 <- function(scenario, model_type, n_sims = 1000){     ###################

# use seed to insure that the same datasets from "historical" distribution
#  are used in perturbation process
set.seed(1234)

dist_of_perturbed <- c()

for(b in 1:n_sims){
   
   
n <- 30
size <- nobs

probs_1 <- c(0.025, 0.135, 0.68, 0.135, 0.025)  # normal
probs_2 <- c(0.1, 0.2, 0.4, 0.2, 0.1)           # triangular
probs_3 <- c(0.17, 0.2, 0.26, 0.2, 0.17)        # near uniform
probs_4 <- c(0.25, 0.2, 0.1, 0.2, 0.25)         # bi-modal
probs_5 <- c(0.3, 0.25, 0.2, 0.15, 0.1)         # right skewed
probs_6 <- c(0.1, 0.15, 0.2, 0.25, 0.3)         # left skewed

mix_1 <- rmultinom(n=5, size=size, prob=probs_1)
mix_2 <- rmultinom(n=5, size=size, prob=probs_2)
mix_3 <- rmultinom(n=5, size=size, prob=probs_3)
mix_4 <- rmultinom(n=5, size=size, prob=probs_4)
mix_5 <- rmultinom(n=5, size=size, prob=probs_5)
mix_6 <- rmultinom(n=5, size=size, prob=probs_6)


# combine the 6 matrices

mixed <- data.frame(mix_1, mix_2, mix_3, mix_4, mix_5, mix_6)

row.names(mixed) <- c("1", "2", "3", "4", "5")
colnames(mixed) <- paste("x", 1:n, sep = "")

data <- as.data.frame(mixed)
values <- c(1,2,3,4,5)
data_long <- data.frame(matrix(nrow = size, ncol = n))

colnames(data_long) <- colnames(mixed)

for(i in names(mixed)){
      data_long[,i] <- sample(rep.int(x=values,times=data[[i]]), size=size)
}
data_xb_p_y <- data.frame(matrix(NA, nrow = nobs, ncol = 3))

data_xb_p_y$xb <- (-1.5 + 0.66*data_long$x1 - 0.64*data_long$x2 + 0.62*data_long$x3 - 
0.6*data_long$x4 + 0.58*data_long$x5 - 0.56*data_long$x6 + 0.54*data_long$x7 - 
0.52*data_long$x8 + 0.5*data_long$x9 - 0.48*data_long$x10 + 0.46*data_long$x11 - 
0.44*data_long$x12 + 0.42*data_long$x13 - 0.4*data_long$x14 + 0.38*data_long$x15 - 
0.36*data_long$x16 + 0.34*data_long$x17 - 0.32*data_long$x18 + 0.3*data_long$x19 - 
0.28*data_long$x20 + 0.26*data_long$x21 - 0.24*data_long$x22 + 0.22*data_long$x23 - 
0.2*data_long$x24 + 0.18*data_long$x25 - 0.16*data_long$x26 + 0.14*data_long$x27 - 
0.12*data_long$x28 + 0.1*data_long$x29 - 0.08*data_long$x30)

data_xb_p_y$p <- exp(data_xb_p_y$xb)/(1 + exp(data_xb_p_y$xb))
data_xb_p_y$y <- rbinom(n=nrow(data_xb_p_y) , size = 1, prob = data_xb_p_y$p)

rep_mat <- sgr::replacement.matrix(Q = 5, p = scenario, fake.model = model_type)
data_pert <- sgr::rdatarepl(Dx = data_long, RM = rep_mat, printfp = FALSE)$Fx

data_pert$xb <- (-1.5 + 0.66*data_pert$x1 - 0.64*data_pert$x2 + 0.62*data_pert$x3 - 
0.6*data_pert$x4 + 0.58*data_pert$x5 - 0.56*data_pert$x6 + 0.54*data_pert$x7 - 
0.52*data_pert$x8 + 0.5*data_pert$x9 - 0.48*data_pert$x10 + 0.46*data_pert$x11 - 
0.44*data_pert$x12 + 0.42*data_pert$x13 - 0.4*data_pert$x14 + 0.38*data_pert$x15 - 
0.36*data_pert$x16 + 0.34*data_pert$x17 - 0.32*data_pert$x18 + 0.3*data_pert$x19 - 
0.28*data_pert$x20 + 0.26*data_pert$x21 - 0.24*data_pert$x22 + 0.22*data_pert$x23 - 
0.2*data_pert$x24 + 0.18*data_pert$x25 - 0.16*data_pert$x26 + 0.14*data_pert$x27 - 
0.12*data_pert$x28 + 0.1*data_pert$x29 - 0.08*data_pert$x30)                     

data_pert$y <- data_xb_p_y$y
data_pert$p <- exp(data_pert$xb)/(1 + exp(data_pert$xb))

fit <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13+x14+x15+x16+x17+x18+x19+x20+
              x21+x22+x23+x24+x25+x26+x27+x28+x29+x30, data = data_pert, family = "binomial")
data_pert$p_hat <- as.vector(predict(fit, type = "response"))
data_pert$y_hat <- ifelse(data_pert$p_hat < 0.5,0,1)

miss <- ifelse(data_pert$y==data_pert$y_hat, 0, 1)
dist_of_perturbed[b] <- mean(miss)
}
dist_of_perturbed
}   

```

```{r, appendix uninformative 10, echo=FALSE, eval=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
uninformative_10 <- list()
ind <- 1
for(scenario in scenario_list_2){
   uninformative_10[[paste0("Uninformative_10_Scenario_",ind)]] <- sim_func_10(
                                           scenario = scenario, 
                                           model_type = "uninformative",
                                           n_sims = 1000)
   ind <- ind+1
}
uninformative_10 <- as.data.frame(uninformative_10)

```

```{r, appendix slight 10, echo=FALSE, eval=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
slight_10 <- list()
ind <- 1
for(scenario in scenario_list_2){
   slight_10[[paste0("Slight_10_Scenario_",ind)]] <- sim_func_10(scenario = scenario, 
                                           model_type = "slight",
                                           n_sims = 1000)
   ind <- ind+1
}
slight_10 <- as.data.frame(slight_10)

```

```{r, appendix extreme 10, echo=FALSE, eval=FALSE, cache=TRUE}

scenario_list_2 <- list(c(0.25,0), c(0.5,0), c(0.75,0), c(1,0), 
                        c(0, 0.25), c(0.25,0.25), c(0.5,0.25), c(0.75,0.25), 
                        c(0, 0.5), c(0.25,0.5), c(0.5, 0.5),
                        c(0, 0.75), c(0.25, 0.75), c(0,1))


# initialize list for output
extreme_10 <- list()
ind <- 1
for(scenario in scenario_list_2){
   extreme_10[[paste0("Extreme_10_Scenario_",ind)]] <- sim_func_10(scenario = scenario, 
                                           model_type = "extreme", 
                                           n_sims = 1000)
   ind <- ind+1
}
extreme_10 <- as.data.frame(extreme_10)

```

```{r, appendix summary 10, echo=FALSE, eval=FALSE, cache=TRUE}

df_10 <- tibble(historical_10, uninformative_10, slight_10, extreme_10) %>% 
            pivot_longer(everything()) %>%
            separate(col = name, into = c("Model", "Scenario"), sep = "_10_")

df_10$Scenario <- factor(df_10$Scenario, levels=c("Historical","Scenario_1", "Scenario_2", 
                                                "Scenario_3","Scenario_4", "Scenario_5", 
                                                "Scenario_6","Scenario_7", "Scenario_8", 
                                                "Scenario_9","Scenario_10", "Scenario_11", 
                                                "Scenario_12","Scenario_13", "Scenario_14"))

df_10$Model <- factor(df_10$Model, levels = c("Historical", "Slight", 
                                            "Uninformative", "Extreme"))

plot_10 <- ggplot(df_10, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('30 Independent Variables, Mixed Distributions') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = 'Boxplots showing misclassification distributions for 1000 simulations of each scenario and replacement \n model (perturbation) type.')


df_10_reduced <- df_10 %>% filter(Scenario == "Historical" |
                                Scenario == "Scenario_1" |
                                Scenario == "Scenario_2" |
                                Scenario == "Scenario_3" |
                                Scenario == "Scenario_4" |
                                Scenario == "Scenario_6" |
                                Scenario == "Scenario_7" |
                                Scenario == "Scenario_8" |
                                Scenario == "Scenario_11")



plot_10_reduced <- ggplot(df_10_reduced, aes(x=Scenario, y=value, fill=Model)) + 
               geom_boxplot() + 
               ggtitle('30 Independent Variables, Mixed Distributions, Unique Scenarios') + 
               scale_y_continuous(name = "Missclassification Rate ", 
                                  breaks = seq(0,1,0.05), 
                                  minor_breaks = seq(0,1,0.01)) +
               scale_x_discrete(name = "Perturbation Scenario", 
                                guide = guide_axis(n.dodge = 1, angle = -65)) +                                                 theme(legend.position = "bottom", legend.title = element_blank()) +
               labs(caption = "Boxplots showing misclassification distributions for 1000 simulations of each unique scenario and replacement \n model (perturbation) type.")


plot_10


```

```{r, appendix hypothesis tests of equivalence 10, eval=FALSE, echo=TRUE}

# large sample test of significance comparing distributions of y=xb
# perturbation scenarios 

## Looking for equivalence of distributions

p_func <- function(first_scenario_vector, second_scenario_vector){
 ts <- ks.test(first_scenario_vector, second_scenario_vector, alternative = "two.sided",
               simulate.p.value=TRUE)

 D <- round(ts$statistic[[1]], digits = 3)
 p <- round(ts$p.value[[1]], digits = 3)
paste0(D," (",p,")")
}


# equivalence of sample means

p_func <- function(first_scenario_vector, second_scenario_vector, Nsims = 1000){
 z <- (mean(first_scenario_vector) - mean(second_scenario_vector))/
       sqrt(var(first_scenario_vector)/Nsims + var(second_scenario_vector)/Nsims)

 p <- ifelse(z > 0, 2*pnorm(z, lower.tail = FALSE), 2*pnorm(z))
 z <- round(z, digits = 3)
 p <- round(p, digits = 3)
paste0(z," (",p,")")
}





data_data <- df_10


################################## 1 versus 5 ################################## 
# slight test statistic and p-value
slight_1_5 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_1")$value,
                      filter(data_data, Model=="Slight", Scenario=="Scenario_5")$value)

# uninformative test statistic and p-value
uninformative_1_5 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_1")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_5")$value)

# extreme test statistic and p-value
extreme_1_5 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_1")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_5")$value)

################################## 2 versus 9 ################################## 
# slight test statistic and p-value
slight_2_9 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_2")$value, 
                      filter(data_data, Model=="Slight", Scenario=="Scenario_9")$value)

# uninformative test statistic and p-value
uninformative_2_9 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_2")$value, 
                             filter(data_data, Model=="Uninformative", Scenario=="Scenario_9")$value)

# extreme test statistic and p-value
extreme_2_9 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_2")$value, 
                       filter(data_data, Model=="Extreme", Scenario=="Scenario_9")$value)

################################## 3 versus 12 ################################## 
# slight test statistic and p-value
slight_3_12 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_3")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_12")$value)

# uninformative test statistic and p-value
uninformative_3_12 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_3")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_12")$value)

# extreme test statistic and p-value
extreme_3_12 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_3")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_12")$value)

################################## 4 versus 14 ################################## 
# slight test statistic and p-value
slight_4_14 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_4")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_14")$value)

# uninformative test statistic and p-value
uninformative_4_14 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_4")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_14")$value)

# extreme test statistic and p-value
extreme_4_14 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_4")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_14")$value)

################################## 7 versus 10 ################################## 
# slight test statistic and p-value
slight_7_10 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_7")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_10")$value)

# uninformative test statistic and p-value
uninformative_7_10 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_7")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_10")$value)

# extreme test statistic and p-value
extreme_7_10 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_7")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_10")$value)

################################## 8 versus 13 ################################## 
# slight test statistic and p-value
slight_8_13 <- p_func(filter(data_data, Model=="Slight", Scenario=="Scenario_8")$value, 
                       filter(data_data, Model=="Slight", Scenario=="Scenario_13")$value)

# uninformative test statistic and p-value
uninformative_8_13 <- p_func(filter(data_data, Model=="Uninformative", Scenario=="Scenario_8")$value, 
                              filter(data_data, Model=="Uninformative", Scenario=="Scenario_13")$value)

# extreme test statistic and p-value
extreme_8_13 <- p_func(filter(data_data, Model=="Extreme", Scenario=="Scenario_8")$value, 
                        filter(data_data, Model=="Extreme", Scenario=="Scenario_13")$value)

##################################################################################################

tests10 <- tribble(
   ~Scenario, ~Perturbation,  ~value,
   "1 vs 5",  "Slight",        slight_1_5,
   "1 vs 5",  "Uninformative", uninformative_1_5,
   "1 vs 5",  "Extreme",       extreme_1_5,
   "2 vs 9",  "Slight",        slight_2_9, 
   "2 vs 9",  "Uninformative", uninformative_2_9,
   "2 vs 9",  "Extreme",       extreme_2_9,
   "3 vs 12", "Slight",        slight_3_12,
   "3 vs 12", "Uninformative", uninformative_3_12,
   "3 vs 12", "Extreme",       extreme_3_12,
   "4 vs 14", "Slight",        slight_4_14,
   "4 vs 14", "Uninformative", uninformative_4_14,
   "4 vs 14", "Extreme",       extreme_4_14,
   "7 vs 10", "Slight",        slight_7_10,
   "7 vs 10", "Uninformative", uninformative_7_10,
   "7 vs 10", "Extreme",       extreme_7_10,
   "8 vs 13", "Slight",        slight_8_13,
   "8 vs 13", "Uninformative", uninformative_8_13,
   "8 vs 13", "Extreme",       extreme_8_13)


tests_w <- pivot_wider(tests10, names_from = Perturbation, values_from = value)

#################################################################################################

tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations: Kolmogorov-Smirnov 
hypothesis test of difference of distributions for equivalent perturbation scenarios - Thirty independent ordinal variables with mixeded distributions - Test statistic (P-value).")

tests_w_table <- xtable::xtable(tests_w, caption = "1000 Observations and 1000 Simulations: Large sample hypothesis tests of  equivalent sample mean for equivalent perturbation scenarios - Thirty independent ordinal variables with mixeded distributions - Test statistic (P-value).")

xtable::print.xtable(tests_w_table, include.rownames = FALSE, caption.placement = "top",
                     table.placement = "h")

```


